{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/BlueLake/source/apple-touch-icon.png","path":"apple-touch-icon.png","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/favicon.ico","path":"favicon.ico","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/iconfont/iconfont.eot","path":"iconfont/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/iconfont/iconfont.svg","path":"iconfont/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/iconfont/iconfont.ttf","path":"iconfont/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/iconfont/iconfont.woff","path":"iconfont/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/js/search.json.js","path":"js/search.json.js","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/js/toctotop.js","path":"js/toctotop.js","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/js/totop.js","path":"js/totop.js","modified":1,"renderable":1},{"_id":"themes/BlueLake/source/img/bg.jpg","path":"img/bg.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"d628a4f6bf480dbb08c44a46a8723c31f6efb40c","modified":1546588793510},{"_id":"themes/BlueLake/LICENSE","hash":"3e191ca3f51efc111863c4941051291a696ef43e","modified":1545714694085},{"_id":"themes/BlueLake/README.en.md","hash":"b9f84036214ec79a8c319c5383696e0076305dfe","modified":1545714694085},{"_id":"themes/BlueLake/README.md","hash":"152969bd5a7e94a595d058f085c517b65d3b61d2","modified":1545714694085},{"_id":"themes/BlueLake/_config.yml","hash":"fd27090e41115ce736c955d838e244623b854e9d","modified":1551329577419},{"_id":"themes/BlueLake/package.json","hash":"e06eea20c64b2821631a49e8902e645bad2c5102","modified":1545714694096},{"_id":"source/_posts/Hello-Flink.md","hash":"70ffc099253a0f0c55bb94307575d2c51da44cb4","modified":1557812660290},{"_id":"source/_posts/SparkStreaming反压机制详解.md","hash":"8cdadc116d21aa0817bbfc6eeeff95652f4f0417","modified":1550197465135},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度.md","hash":"4b6fbd4fe15dfa2e892beef3cb9eefb77f24b9ab","modified":1550731044268},{"_id":"themes/BlueLake/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1545714694078},{"_id":"themes/BlueLake/.git/config","hash":"cb5d8538f60766fe2a079a1894a586d81b258abf","modified":1545714694080},{"_id":"themes/BlueLake/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1545714689659},{"_id":"themes/BlueLake/.git/index","hash":"d5a09d36cad795c0a37d55b1281d48c4f0bc6e03","modified":1545714892091},{"_id":"themes/BlueLake/.git/packed-refs","hash":"e3b56de922e8682abdbf326de2487788e3f46c69","modified":1545714694076},{"_id":"source/_drafts/kylin启动过程.md","hash":"75014a328c5bf8b6d0571d52fd2c79cf7db4e952","modified":1545806086411},{"_id":"source/_drafts/kylin支持的聚合函数.md","hash":"7e15b49a15f330ca132639deb618751d1dba3278","modified":1545725929071},{"_id":"themes/BlueLake/layout/archive.jade","hash":"0497469c869f0ac28f150295dbddf6920e6582c1","modified":1545714694094},{"_id":"themes/BlueLake/layout/base.jade","hash":"2e65a06a499fbb67c72f8345d71222e40e9ef523","modified":1545714694094},{"_id":"themes/BlueLake/layout/category.jade","hash":"384e2e2588ecab3f518f03f11f2b052d3827fad8","modified":1545714694095},{"_id":"themes/BlueLake/layout/index.jade","hash":"ba1ea647af5c134b1a950638ea864663b29d4e22","modified":1545714694095},{"_id":"themes/BlueLake/layout/page.jade","hash":"7d2a48f6a902605fd6cfc237e3c2f9c02d76492e","modified":1545714694095},{"_id":"themes/BlueLake/layout/post.jade","hash":"3025e7e259d69551a35f17db3c3981aaa77fe7bc","modified":1545714694096},{"_id":"themes/BlueLake/layout/tag.jade","hash":"835da21846c730f0e3e344dc7e2e59154030b4f7","modified":1545714694096},{"_id":"themes/BlueLake/languages/de-DE.yml","hash":"3e78b20edc66b153cb6b708734ad9aa5381266bc","modified":1545714694086},{"_id":"themes/BlueLake/languages/en.yml","hash":"88f4e4cffce5598f949192d7e76c863a0d409981","modified":1545714694086},{"_id":"themes/BlueLake/languages/es-ES.yml","hash":"83ee131065111147d20ec13c4634a27ee4fd541d","modified":1545714694086},{"_id":"themes/BlueLake/languages/fr-FR.yml","hash":"d9f90ef2c6b4d8c95d142d021a5f47dda8462715","modified":1545714694086},{"_id":"themes/BlueLake/languages/ko.yml","hash":"20c7df4087ee65d75e96f68c71fdb050eb63677f","modified":1545714694087},{"_id":"themes/BlueLake/languages/tr.yml","hash":"1c623122f1ff7878595de6783bd83afc3a746373","modified":1545714694087},{"_id":"themes/BlueLake/languages/zh-CN.yml","hash":"0755af57d92a07ecff0e327f78eb25b0623a5852","modified":1545714694087},{"_id":"themes/BlueLake/languages/zh-TW.yml","hash":"61f419488d4a8f62c2b90ee766b6e68ba2e88bd7","modified":1545714694087},{"_id":"themes/BlueLake/source/apple-touch-icon.png","hash":"98f0ecbdcdc1a0e8e52f4d786cbc011e5e06fa65","modified":1545714694097},{"_id":"themes/BlueLake/source/favicon.ico","hash":"94e5d25d942bff5479470322454c951f2ddebac6","modified":1545714694098},{"_id":"source/_posts/SparkStreaming反压机制详解/inputRate.png","hash":"9c41e748a7e3f64c399eaae1b8b6c0bf9ded2657","modified":1534929426000},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/RDDUml","hash":"3a6116083e5a633fef36753cb157e34bbb339fa1","modified":1550458533914},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/RDDUml.png","hash":"4ec3e6610a89ca9a54e9d1370ecd0b3b6610b9d7","modified":1550218682367},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SchedulerUML","hash":"6d15aecbd8a5e299a06f7a16b5d26bbc59e02bc6","modified":1550460061414},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SparkContextUML.png","hash":"513f1cc1cb43db78aaa40c33601aaedf5c74548a","modified":1550539598403},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SchedulerUML.png","hash":"ad37fded2c56e662e5a2b973e09047b0dd0ce2ea","modified":1550460053570},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SplitUML","hash":"1f25380fe25b85aa72b85e42646ebf8eb22f39ac","modified":1550458531506},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/TaskUML","hash":"373a88b5c295d1d738ba8360be982be6350a0278","modified":1550458600141},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SplitUML.png","hash":"c1b42b0716b42786e070a60268cc41f733f954c8","modified":1550218674691},{"_id":"themes/BlueLake/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1545714689662},{"_id":"themes/BlueLake/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1545714689660},{"_id":"themes/BlueLake/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1545714689664},{"_id":"themes/BlueLake/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1545714689664},{"_id":"themes/BlueLake/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1545714689662},{"_id":"themes/BlueLake/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1545714689665},{"_id":"themes/BlueLake/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1545714689661},{"_id":"themes/BlueLake/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1545714689663},{"_id":"themes/BlueLake/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1545714689663},{"_id":"themes/BlueLake/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1545714689665},{"_id":"themes/BlueLake/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1545714689659},{"_id":"themes/BlueLake/.git/logs/HEAD","hash":"c377e803ea31fa04342ca936bd89065622bc6868","modified":1545714694079},{"_id":"themes/BlueLake/layout/_widget/archive.jade","hash":"082ae16dad18ada28913772675861d7230134bea","modified":1545714694093},{"_id":"themes/BlueLake/layout/_widget/category.jade","hash":"ba43bd011d64cd86fa420677c9000d328f4f6114","modified":1545714694093},{"_id":"themes/BlueLake/layout/_widget/links.jade","hash":"ff46afdedc1ab3c075ffed686b98f23aed066124","modified":1545714694093},{"_id":"themes/BlueLake/layout/_widget/recent_comments.jade","hash":"f8ae55d5514fe493651ec04fbe73cb5fc482f7cd","modified":1545714694093},{"_id":"themes/BlueLake/layout/_widget/recent_posts.jade","hash":"a0309137277323f2fd61a3c6691e1bc51026f711","modified":1545714694094},{"_id":"themes/BlueLake/layout/_widget/tag.jade","hash":"3df9a00a21d3bc151026b2d403a99c28fe1ccd13","modified":1545714694094},{"_id":"themes/BlueLake/layout/_widget/weibo.jade","hash":"53e99461ae7f8efb2a1e78ad3090dd93d18bcd5c","modified":1545714694094},{"_id":"themes/BlueLake/layout/_partial/after_footer.jade","hash":"26ae121ecc5bbe351927dd273d58871f69454500","modified":1545714694087},{"_id":"themes/BlueLake/layout/_partial/comment_count.jade","hash":"52e4cacd58d5e0061924189ad75e0c3bf622aa7f","modified":1545714694088},{"_id":"themes/BlueLake/layout/_partial/comments.jade","hash":"af9a4a65eba65c5140921326f2b5cae9db5d7d28","modified":1545714694089},{"_id":"themes/BlueLake/layout/_partial/comments_js.jade","hash":"25e28dc48c392a5d10db1ed0f8a5899598d643d5","modified":1545714694090},{"_id":"themes/BlueLake/layout/_partial/footer.jade","hash":"dbc5c401f4d8aa80fe9e73423aadb8b8969f0b62","modified":1545714694091},{"_id":"themes/BlueLake/layout/_partial/helpers.jade","hash":"acdf9e2d52ee86c831fa15ce1570930c5779bc78","modified":1545714694091},{"_id":"themes/BlueLake/layout/_partial/mathjax.jade","hash":"b54b56faff9e47ab3ca3cdd55056c73e60776f3c","modified":1545714694091},{"_id":"themes/BlueLake/layout/_partial/mathjax2.jade","hash":"d6ac5dc4e9c7a1b866f1f92d88988cfb35aded4c","modified":1545714694091},{"_id":"themes/BlueLake/layout/_partial/paginator.jade","hash":"53f9cb77448e84a98da5eb688e2e12b173c555bb","modified":1545714694091},{"_id":"themes/BlueLake/layout/_partial/post_nav.jade","hash":"a2d698c84bb6da08195fe870dbd7215f65388d3f","modified":1545714694092},{"_id":"themes/BlueLake/layout/_partial/search.jade","hash":"1c988c7e1f716036e428ee16b8005a7b1bfb33c7","modified":1545714694092},{"_id":"themes/BlueLake/layout/_partial/share.jade","hash":"28d79fbb9d8ecc5692d3063e439f16224188abac","modified":1545714694092},{"_id":"themes/BlueLake/layout/_partial/tag.jade","hash":"0f0e6770e9d5dd8040e330d71bbbfadd2df36a28","modified":1545714694092},{"_id":"themes/BlueLake/layout/_partial/totop.jade","hash":"3e4141538285aef2bd019832ba62bafd094c6097","modified":1545714694093},{"_id":"themes/BlueLake/source/css/style.styl","hash":"5852cc541b74868e6464c7224b65683ea5aaa8d8","modified":1545714694098},{"_id":"themes/BlueLake/source/css/highlight.styl","hash":"be9ad73454b7029311caafd8e1faa469a5d4f58d","modified":1545714694097},{"_id":"themes/BlueLake/source/iconfont/iconfont.eot","hash":"e664dd848ca65fe3aca4acfc234ff9c18ffd4c33","modified":1545714694099},{"_id":"themes/BlueLake/source/iconfont/iconfont.svg","hash":"2b6a0b21bf63bdf746130117baf432fcb44ad210","modified":1545714694099},{"_id":"themes/BlueLake/source/iconfont/iconfont.ttf","hash":"5770696cc0d19d9c9479912a5cf54c9dd4ab24c4","modified":1545714694100},{"_id":"themes/BlueLake/source/iconfont/iconfont.woff","hash":"df2bd849134cbd02beb385e5061a30b923c99058","modified":1545714694100},{"_id":"themes/BlueLake/source/js/search.json.js","hash":"a0e8dfee9b9845aabd64360d497df7c0767b7235","modified":1545714694102},{"_id":"themes/BlueLake/source/js/toctotop.js","hash":"ad6386bc746ff375715ca9da17af4716ea86e06a","modified":1545714694102},{"_id":"themes/BlueLake/source/js/totop.js","hash":"5b1131830209c2daaf6fe34c5e39ab7c1059bfa4","modified":1545714694102},{"_id":"source/_posts/SparkStreaming反压机制详解/RateController.png","hash":"1d337ec59a94c9355d92589923c7bdf71fccd614","modified":1534836129000},{"_id":"source/_posts/SparkStreaming反压机制详解/maxMessagesPerPartition.png","hash":"e61b88805e387988ddf4f060c68ecf23fdb4b3f0","modified":1534834845000},{"_id":"themes/BlueLake/source/img/bg.jpg","hash":"d23d92484e98adcbea7266ebfdfef7fb3fc42ee0","modified":1545714694101},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/rdd.png","hash":"9f1e93c9765b15a90dcf0fbae5dad1115e1dd45f","modified":1550208900850},{"_id":"themes/BlueLake/.git/objects/pack/pack-79cfddb7f4e2fb8a2187c309c6f3449a8a5850c5.idx","hash":"407997a83a88a8396b35e82e6591f8f0943d5354","modified":1545714694057},{"_id":"themes/BlueLake/.git/refs/heads/master","hash":"c292cfc66fa6a171bcb9e25157b4ee8f09da6755","modified":1545714694079},{"_id":"themes/BlueLake/.git/logs/refs/heads/master","hash":"c377e803ea31fa04342ca936bd89065622bc6868","modified":1545714694079},{"_id":"themes/BlueLake/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1545714694078},{"_id":"themes/BlueLake/.git/logs/refs/remotes/origin/HEAD","hash":"c377e803ea31fa04342ca936bd89065622bc6868","modified":1545714694077},{"_id":"themes/BlueLake/.git/objects/pack/pack-79cfddb7f4e2fb8a2187c309c6f3449a8a5850c5.pack","hash":"4a772887b78fe207aeb39f26ef60cd34329ec6e8","modified":1545714694056}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"SparkStreaming反压机制详解","date":"2019-01-04T04:24:03.000Z","_content":"\n# 背景概念\n\n* DStream： 表示一系列时间序列上连续的RDDs。\n* Batch Duration：spark streaming的核心参数，设置流数据被分成多个batch的时间间隔，每个spark引擎处理的就是这个时间间隔内的数据。\n* InputDStream：InputDStream继承自DStream，是所有输入流的基类，代表从源接收到的原始数据流DStreams，每一个InputDStream关联到单个Receiver对象，从源数据接收数据并存储到spark内存，等待处理。\n\n# 反压是什么\n反压可以限制每个batch接收到的消息量\n\n\tSpark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。\n\n# 为什么设置反压\n如果在一个batch内收到的消息过多，这就需要为executor分配更多内存，可能会导致其他spark streaming应用程序资源分配不足，甚至有OOM的风险。反压机制就可以动态控制batch接收消息速率，来适配集群处理能力。\n\n\n\n# 设置\n\n* 开启反压\n\nSparkConf.set(\"spark.streaming.backpressure.enabled\", \"true\")\n\n* 设置每个kafka partition读取消息的最大速率:\n\nSparkConf.set(\"spark.streaming.kafka.maxRatePerPartition\", \"spark.streaming.kafka.maxRatePerPartition\")\n\n\t这个值要结合spark Streaming处理消息的速率和batchDuration，\n\t尽量保证读取的每个partition数据在batchDuration时间内处理完，\n\t这个参数需要不断调整，以做到尽可能高的吞吐量.\n\n\n# 基本原理\n\n\n\n## 速率预估\n1. rateController （in DirectKafkaInputDStream）\n2. RateController : 继承自StreamingListener. 用于处理BatchCompleted事件(见下图)。\n3. RateEstimator\n4. PIDRateEstimator\n\n\n\n{% asset_img RateController.png %}\n\n## 限流\nmaxMessagesPerPartition (in DirectKafkaInputDStream.scala)\n\n\n{% asset_img maxMessagesPerPartition.png %}\n\ncom.google.common.util.concurrent.RateLimiter\n\nRateLimiter是guava提供的基于令牌桶算法的实现类，可以非常简单的完成限流特技，并且根据系统的实际情况来调整生成token的速率。\n\n\n\n# 需要注意的坑\n## 从多个Topic创建Stream\n根据 ***maxMessagesPerPartition*** 代码可知，每次根据上一个速率来预估速率，如果多个topic速率相差过大，会造成预估的速率忽大忽小(如下图)，速率很不稳定，整体上接近多个速率的平均值。\n{% asset_img inputRate.png %}\n\n## 一个Job多个Stream\n由于只能配置一个参数，所以只能配置一个各topic对应partion速率的折中值，若不同topic的partition速率差别太大，则很难两全。\n\n\tps:按小的设，大的会频繁甚至始终命中背压。按大的设，小的起不到背压效果而OOM。\n\n## maxRatePerPartition参数设置\n\n这个是速率，不需要乘以batch duration了。\n\n\n# 参考文献\n1. 再谈Spark Streaming Kafka反压 https://www.jianshu.com/p/c0b724137416\n2. Spark Streaming性能优化: 如何在生产环境下应对流数据峰值巨变 https://www.cnblogs.com/itboys/p/6486089.html\n3. ","source":"_posts/SparkStreaming反压机制详解.md","raw":"---\ntitle: SparkStreaming反压机制详解\ndate: 2019-01-04 12:24:03\ntags: spark\n---\n\n# 背景概念\n\n* DStream： 表示一系列时间序列上连续的RDDs。\n* Batch Duration：spark streaming的核心参数，设置流数据被分成多个batch的时间间隔，每个spark引擎处理的就是这个时间间隔内的数据。\n* InputDStream：InputDStream继承自DStream，是所有输入流的基类，代表从源接收到的原始数据流DStreams，每一个InputDStream关联到单个Receiver对象，从源数据接收数据并存储到spark内存，等待处理。\n\n# 反压是什么\n反压可以限制每个batch接收到的消息量\n\n\tSpark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。\n\n# 为什么设置反压\n如果在一个batch内收到的消息过多，这就需要为executor分配更多内存，可能会导致其他spark streaming应用程序资源分配不足，甚至有OOM的风险。反压机制就可以动态控制batch接收消息速率，来适配集群处理能力。\n\n\n\n# 设置\n\n* 开启反压\n\nSparkConf.set(\"spark.streaming.backpressure.enabled\", \"true\")\n\n* 设置每个kafka partition读取消息的最大速率:\n\nSparkConf.set(\"spark.streaming.kafka.maxRatePerPartition\", \"spark.streaming.kafka.maxRatePerPartition\")\n\n\t这个值要结合spark Streaming处理消息的速率和batchDuration，\n\t尽量保证读取的每个partition数据在batchDuration时间内处理完，\n\t这个参数需要不断调整，以做到尽可能高的吞吐量.\n\n\n# 基本原理\n\n\n\n## 速率预估\n1. rateController （in DirectKafkaInputDStream）\n2. RateController : 继承自StreamingListener. 用于处理BatchCompleted事件(见下图)。\n3. RateEstimator\n4. PIDRateEstimator\n\n\n\n{% asset_img RateController.png %}\n\n## 限流\nmaxMessagesPerPartition (in DirectKafkaInputDStream.scala)\n\n\n{% asset_img maxMessagesPerPartition.png %}\n\ncom.google.common.util.concurrent.RateLimiter\n\nRateLimiter是guava提供的基于令牌桶算法的实现类，可以非常简单的完成限流特技，并且根据系统的实际情况来调整生成token的速率。\n\n\n\n# 需要注意的坑\n## 从多个Topic创建Stream\n根据 ***maxMessagesPerPartition*** 代码可知，每次根据上一个速率来预估速率，如果多个topic速率相差过大，会造成预估的速率忽大忽小(如下图)，速率很不稳定，整体上接近多个速率的平均值。\n{% asset_img inputRate.png %}\n\n## 一个Job多个Stream\n由于只能配置一个参数，所以只能配置一个各topic对应partion速率的折中值，若不同topic的partition速率差别太大，则很难两全。\n\n\tps:按小的设，大的会频繁甚至始终命中背压。按大的设，小的起不到背压效果而OOM。\n\n## maxRatePerPartition参数设置\n\n这个是速率，不需要乘以batch duration了。\n\n\n# 参考文献\n1. 再谈Spark Streaming Kafka反压 https://www.jianshu.com/p/c0b724137416\n2. Spark Streaming性能优化: 如何在生产环境下应对流数据峰值巨变 https://www.cnblogs.com/itboys/p/6486089.html\n3. ","slug":"SparkStreaming反压机制详解","published":1,"updated":"2019-02-15T02:24:25.135Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvne0b360000m7z4s6s1pbj4","content":"<h1 id=\"背景概念\"><a href=\"#背景概念\" class=\"headerlink\" title=\"背景概念\"></a>背景概念</h1><ul>\n<li>DStream： 表示一系列时间序列上连续的RDDs。</li>\n<li>Batch Duration：spark streaming的核心参数，设置流数据被分成多个batch的时间间隔，每个spark引擎处理的就是这个时间间隔内的数据。</li>\n<li>InputDStream：InputDStream继承自DStream，是所有输入流的基类，代表从源接收到的原始数据流DStreams，每一个InputDStream关联到单个Receiver对象，从源数据接收数据并存储到spark内存，等待处理。</li>\n</ul>\n<h1 id=\"反压是什么\"><a href=\"#反压是什么\" class=\"headerlink\" title=\"反压是什么\"></a>反压是什么</h1><p>反压可以限制每个batch接收到的消息量</p>\n<pre><code>Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。\n</code></pre><h1 id=\"为什么设置反压\"><a href=\"#为什么设置反压\" class=\"headerlink\" title=\"为什么设置反压\"></a>为什么设置反压</h1><p>如果在一个batch内收到的消息过多，这就需要为executor分配更多内存，可能会导致其他spark streaming应用程序资源分配不足，甚至有OOM的风险。反压机制就可以动态控制batch接收消息速率，来适配集群处理能力。</p>\n<h1 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a>设置</h1><ul>\n<li>开启反压</li>\n</ul>\n<p>SparkConf.set(“spark.streaming.backpressure.enabled”, “true”)</p>\n<ul>\n<li>设置每个kafka partition读取消息的最大速率:</li>\n</ul>\n<p>SparkConf.set(“spark.streaming.kafka.maxRatePerPartition”, “spark.streaming.kafka.maxRatePerPartition”)</p>\n<pre><code>这个值要结合spark Streaming处理消息的速率和batchDuration，\n尽量保证读取的每个partition数据在batchDuration时间内处理完，\n这个参数需要不断调整，以做到尽可能高的吞吐量.\n</code></pre><h1 id=\"基本原理\"><a href=\"#基本原理\" class=\"headerlink\" title=\"基本原理\"></a>基本原理</h1><h2 id=\"速率预估\"><a href=\"#速率预估\" class=\"headerlink\" title=\"速率预估\"></a>速率预估</h2><ol>\n<li>rateController （in DirectKafkaInputDStream）</li>\n<li>RateController : 继承自StreamingListener. 用于处理BatchCompleted事件(见下图)。</li>\n<li>RateEstimator</li>\n<li>PIDRateEstimator</li>\n</ol>\n<img src=\"/2019/01/04/SparkStreaming反压机制详解/RateController.png\">\n<h2 id=\"限流\"><a href=\"#限流\" class=\"headerlink\" title=\"限流\"></a>限流</h2><p>maxMessagesPerPartition (in DirectKafkaInputDStream.scala)</p>\n<img src=\"/2019/01/04/SparkStreaming反压机制详解/maxMessagesPerPartition.png\">\n<p>com.google.common.util.concurrent.RateLimiter</p>\n<p>RateLimiter是guava提供的基于令牌桶算法的实现类，可以非常简单的完成限流特技，并且根据系统的实际情况来调整生成token的速率。</p>\n<h1 id=\"需要注意的坑\"><a href=\"#需要注意的坑\" class=\"headerlink\" title=\"需要注意的坑\"></a>需要注意的坑</h1><h2 id=\"从多个Topic创建Stream\"><a href=\"#从多个Topic创建Stream\" class=\"headerlink\" title=\"从多个Topic创建Stream\"></a>从多个Topic创建Stream</h2><p>根据 <strong><em>maxMessagesPerPartition</em></strong> 代码可知，每次根据上一个速率来预估速率，如果多个topic速率相差过大，会造成预估的速率忽大忽小(如下图)，速率很不稳定，整体上接近多个速率的平均值。<br><img src=\"/2019/01/04/SparkStreaming反压机制详解/inputRate.png\"></p>\n<h2 id=\"一个Job多个Stream\"><a href=\"#一个Job多个Stream\" class=\"headerlink\" title=\"一个Job多个Stream\"></a>一个Job多个Stream</h2><p>由于只能配置一个参数，所以只能配置一个各topic对应partion速率的折中值，若不同topic的partition速率差别太大，则很难两全。</p>\n<pre><code>ps:按小的设，大的会频繁甚至始终命中背压。按大的设，小的起不到背压效果而OOM。\n</code></pre><h2 id=\"maxRatePerPartition参数设置\"><a href=\"#maxRatePerPartition参数设置\" class=\"headerlink\" title=\"maxRatePerPartition参数设置\"></a>maxRatePerPartition参数设置</h2><p>这个是速率，不需要乘以batch duration了。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ol>\n<li>再谈Spark Streaming Kafka反压 <a href=\"https://www.jianshu.com/p/c0b724137416\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/c0b724137416</a></li>\n<li>Spark Streaming性能优化: 如何在生产环境下应对流数据峰值巨变 <a href=\"https://www.cnblogs.com/itboys/p/6486089.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/itboys/p/6486089.html</a></li>\n<li></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"背景概念\"><a href=\"#背景概念\" class=\"headerlink\" title=\"背景概念\"></a>背景概念</h1><ul>\n<li>DStream： 表示一系列时间序列上连续的RDDs。</li>\n<li>Batch Duration：spark streaming的核心参数，设置流数据被分成多个batch的时间间隔，每个spark引擎处理的就是这个时间间隔内的数据。</li>\n<li>InputDStream：InputDStream继承自DStream，是所有输入流的基类，代表从源接收到的原始数据流DStreams，每一个InputDStream关联到单个Receiver对象，从源数据接收数据并存储到spark内存，等待处理。</li>\n</ul>\n<h1 id=\"反压是什么\"><a href=\"#反压是什么\" class=\"headerlink\" title=\"反压是什么\"></a>反压是什么</h1><p>反压可以限制每个batch接收到的消息量</p>\n<pre><code>Spark Streaming 从v1.5开始引入反压机制（back-pressure）,通过动态控制数据接收速率来适配集群数据处理能力。\n</code></pre><h1 id=\"为什么设置反压\"><a href=\"#为什么设置反压\" class=\"headerlink\" title=\"为什么设置反压\"></a>为什么设置反压</h1><p>如果在一个batch内收到的消息过多，这就需要为executor分配更多内存，可能会导致其他spark streaming应用程序资源分配不足，甚至有OOM的风险。反压机制就可以动态控制batch接收消息速率，来适配集群处理能力。</p>\n<h1 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a>设置</h1><ul>\n<li>开启反压</li>\n</ul>\n<p>SparkConf.set(“spark.streaming.backpressure.enabled”, “true”)</p>\n<ul>\n<li>设置每个kafka partition读取消息的最大速率:</li>\n</ul>\n<p>SparkConf.set(“spark.streaming.kafka.maxRatePerPartition”, “spark.streaming.kafka.maxRatePerPartition”)</p>\n<pre><code>这个值要结合spark Streaming处理消息的速率和batchDuration，\n尽量保证读取的每个partition数据在batchDuration时间内处理完，\n这个参数需要不断调整，以做到尽可能高的吞吐量.\n</code></pre><h1 id=\"基本原理\"><a href=\"#基本原理\" class=\"headerlink\" title=\"基本原理\"></a>基本原理</h1><h2 id=\"速率预估\"><a href=\"#速率预估\" class=\"headerlink\" title=\"速率预估\"></a>速率预估</h2><ol>\n<li>rateController （in DirectKafkaInputDStream）</li>\n<li>RateController : 继承自StreamingListener. 用于处理BatchCompleted事件(见下图)。</li>\n<li>RateEstimator</li>\n<li>PIDRateEstimator</li>\n</ol>\n<img src=\"/2019/01/04/SparkStreaming反压机制详解/RateController.png\">\n<h2 id=\"限流\"><a href=\"#限流\" class=\"headerlink\" title=\"限流\"></a>限流</h2><p>maxMessagesPerPartition (in DirectKafkaInputDStream.scala)</p>\n<img src=\"/2019/01/04/SparkStreaming反压机制详解/maxMessagesPerPartition.png\">\n<p>com.google.common.util.concurrent.RateLimiter</p>\n<p>RateLimiter是guava提供的基于令牌桶算法的实现类，可以非常简单的完成限流特技，并且根据系统的实际情况来调整生成token的速率。</p>\n<h1 id=\"需要注意的坑\"><a href=\"#需要注意的坑\" class=\"headerlink\" title=\"需要注意的坑\"></a>需要注意的坑</h1><h2 id=\"从多个Topic创建Stream\"><a href=\"#从多个Topic创建Stream\" class=\"headerlink\" title=\"从多个Topic创建Stream\"></a>从多个Topic创建Stream</h2><p>根据 <strong><em>maxMessagesPerPartition</em></strong> 代码可知，每次根据上一个速率来预估速率，如果多个topic速率相差过大，会造成预估的速率忽大忽小(如下图)，速率很不稳定，整体上接近多个速率的平均值。<br><img src=\"/2019/01/04/SparkStreaming反压机制详解/inputRate.png\"></p>\n<h2 id=\"一个Job多个Stream\"><a href=\"#一个Job多个Stream\" class=\"headerlink\" title=\"一个Job多个Stream\"></a>一个Job多个Stream</h2><p>由于只能配置一个参数，所以只能配置一个各topic对应partion速率的折中值，若不同topic的partition速率差别太大，则很难两全。</p>\n<pre><code>ps:按小的设，大的会频繁甚至始终命中背压。按大的设，小的起不到背压效果而OOM。\n</code></pre><h2 id=\"maxRatePerPartition参数设置\"><a href=\"#maxRatePerPartition参数设置\" class=\"headerlink\" title=\"maxRatePerPartition参数设置\"></a>maxRatePerPartition参数设置</h2><p>这个是速率，不需要乘以batch duration了。</p>\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ol>\n<li>再谈Spark Streaming Kafka反压 <a href=\"https://www.jianshu.com/p/c0b724137416\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/c0b724137416</a></li>\n<li>Spark Streaming性能优化: 如何在生产环境下应对流数据峰值巨变 <a href=\"https://www.cnblogs.com/itboys/p/6486089.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/itboys/p/6486089.html</a></li>\n<li></li>\n</ol>\n"},{"title":"spark源码解析alpha-0.1","date":"2019-02-15T02:26:07.000Z","_content":"\n\n\nSpark源码：https://github.com/apache/spark.git \n\n版本号：alpha-0.1\n\n\n\nSpark最核心的概念是RDD（分布式弹性数据集）数据模型，在alpha-0.1版本中实现了RDD数据模型及在其上的任务调度系统，另外还实现了Broadcast和Accumulator工具以及SparkContext接口和spark-shell接口，下面对其分别做介绍。\n\n# RDD与任务调度\n\n​\t百度百科对RDD介绍如下：*RDD(Resilient Distributed Datasets)，弹性分布式数据集，是分布式内存的一个抽象概念。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，只能通过在其他RDD执行确定的转换操作（如map、join和group by）而创建，然而这些限制使得实现容错的开销很低。​*\n\n​        我们可以将RDD看成一个链表，链表的每个节点在上一个节点数据的基础上增加了一些操作而生成。计算最终数据时，只需按照链表上的操作顺序对数据进行计算即可。\n\ndata ->f1(data)->f2(f1(data))......->fn(...f1(data)...)\n\nRDD将数据分成多个split，每个split可以单独形成操作链表，及整个RDD成为了一组链表。\n\n不同的操作产生不同的RDD即形成了RDD的类体系。\n\n## RDD的API\n\n\nRDD的函数可以分为两类，一类是用户接口算子，包括对数据进行操作的transform算子，如map、filter、reduce等和触发任务执行的Action算子如 count、collect、foreach等；另一类是任务执行时需要的函数，如split、iterator等，子类通过复写这些函数来实现不同的子RDD。在alpha-0.1版本中RDD实现了以下函数:\n\n\n**执行函数（子类重载）**\n\n- def splits: Array[Split]    获取数据分片\n- def iterator(split: Split): Iterator[T]   数据分片上的迭代器\n- def preferredLocations(split: Split): Seq[String]  数据分片引用的数据地址\n- def taskStarted(split: Split, slot: SlaveOffer) 任务是否启动\n\n\n**Transform算子**\n\n* def map(f: T => U):MappedRDD\n* def filter(f: T => Boolean):FilteredRDD\n* def aggregateSplit():SplitRDD\n* def cache():CachedRDD\n* def def sample(withReplacement: Boolean, frac: Double,seed: Int):SampledRDD\n* def flatMap(f: T => Traversable[U]):FlatMappedRDD\n\n\n**Action算子**\n\n* def foreach(f: T => Unit):Unit\n* def collect(): Array[T]\n* def toArray(): Array[T]\n* def reduce(f: (T, T) => T): T\n* def take(num: Int): Array[T]\n* def first: T\n* def count(): Long\n* def union(other: RDD[T]):UnionRDD\n* def ++(other: RDD[T]):UnionRDD\n* def cartesian(other: RDD[U]):CartesianRDD\n\n\n\n## RDD类体系\n\n\n\nRDD分为两大类，一类根据外部数据生成，是RDD的起点，在alpha-0.1版本中只有HdfsTextFile 和ParallelArray；另一类是在RDD增加操作产生，如 MappedRDD、FilteredRDD等，该类RDD和transform算子相对应。继承体系如下：\n\n{% asset_img  RDDUml.png %}\n\n{% asset_img  SplitUML.png %}\n\nalpha-0.1中实现的RDD有：\n\n* HdfsTextFile(sc: SparkContext, path: String)\n* ParallelArray(sc: SparkContext, data: Seq[T], numSlices: Int)\n* MappedRDD(prev: RDD[T], f: T => U)\n* FilteredRDD(prev: RDD[T], f: T => Boolean)\n* FlatMappedRDD(prev: RDD[T], f: T => Traversable[U])\n* SplitRDD(prev: RDD[T])\n* SampledRDD(prev: RDD[T], withReplacement: Boolean, frac: Double, seed: Int)\n* CachedRDD(prev: RDD[T])\n* UnionRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[T])\n* CartesianRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[U])\n\n\n\n## 任务调度\n\n如上所述，Action算子会产生任务，并触发任务的提交。下面我们以foreach为例，追踪任务调度流程。\n\n\n\n1. 在action算子（foreach）中，对每个分区(split)生成Task（ForeachTask）实例，并调用sc（SparkContext）中的 runTaskObjects函数来执行任务。\n\n```scala\ndef foreach(f: T => Unit) {\n  val cleanF = sc.clean(f)\n  val tasks = splits.map(s => new ForeachTask(this, s, cleanF)).toArray\n  sc.runTaskObjects(tasks)\n}\n```\n\n2、在SparkContext的 runTaskObjects函数中，调用 Scheduler实例的 runTasks函数来执行任务。\n\n```scala\nclass SparkContext(master: String, frameworkName: String) extends Logging {\n\n  private[spark] def runTaskObjects[T: ClassManifest](tasks: Seq[Task[T]])\n      : Array[T] = {\n    logInfo(\"Running \" + tasks.length + \" tasks in parallel\")\n    val start = System.nanoTime\n    val result = scheduler.runTasks(tasks.toArray)\n    logInfo(\"Tasks finished in \" + (System.nanoTime - start) / 1e9 + \" s\")\n    return result\n  }\n}\n```\n\n\n\n## Scheduler与Task类体系\n\n{% asset_img  SchedulerUML.png %}\n\n# SparkContext\n\nSparkContext有两大职责，一方面管理着spark运行所需的环境，在alpha-0.1中主要是 任务调度器Scheduler；另一方面向用户提供了编程API。主要函数如下：\n\n**运行环境**\n\n* scheduler: Scheduler   任务调度器 \n* def runTasks(tasks: Array[() => T]): Array[T]   任务执行函数（由rdd的action算子调用）\n\n**编程API**\n\n* def textFile(path: String) : HdfsTextFile\n* def parallelize(seq: Seq[T], numSlices: Int):ParallelArray[T]\n* def parallelize(seq: Seq[T]):ParallelArray[T]\n* def accumulator():Accumulator   \n* def broadcast(value: T):CentralizedHDFSBroadcast\n\n\n\n{% asset_img  SparkContextUML.png %}\n\n\n\n# 参考文献\n\n* Spark-alpha-0.1源码解读：https://www.jianshu.com/p/795302f94fa1\n* 百度百科：https://baike.baidu.com/item/RDD/5840158\n\n","source":"_posts/spark源码解析alpha-0-1RDD与任务调度.md","raw":"---\ntitle: spark源码解析alpha-0.1\ndate: 2019-02-15 10:26:07\ntags: spark,原理,源码\n---\n\n\n\nSpark源码：https://github.com/apache/spark.git \n\n版本号：alpha-0.1\n\n\n\nSpark最核心的概念是RDD（分布式弹性数据集）数据模型，在alpha-0.1版本中实现了RDD数据模型及在其上的任务调度系统，另外还实现了Broadcast和Accumulator工具以及SparkContext接口和spark-shell接口，下面对其分别做介绍。\n\n# RDD与任务调度\n\n​\t百度百科对RDD介绍如下：*RDD(Resilient Distributed Datasets)，弹性分布式数据集，是分布式内存的一个抽象概念。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，只能通过在其他RDD执行确定的转换操作（如map、join和group by）而创建，然而这些限制使得实现容错的开销很低。​*\n\n​        我们可以将RDD看成一个链表，链表的每个节点在上一个节点数据的基础上增加了一些操作而生成。计算最终数据时，只需按照链表上的操作顺序对数据进行计算即可。\n\ndata ->f1(data)->f2(f1(data))......->fn(...f1(data)...)\n\nRDD将数据分成多个split，每个split可以单独形成操作链表，及整个RDD成为了一组链表。\n\n不同的操作产生不同的RDD即形成了RDD的类体系。\n\n## RDD的API\n\n\nRDD的函数可以分为两类，一类是用户接口算子，包括对数据进行操作的transform算子，如map、filter、reduce等和触发任务执行的Action算子如 count、collect、foreach等；另一类是任务执行时需要的函数，如split、iterator等，子类通过复写这些函数来实现不同的子RDD。在alpha-0.1版本中RDD实现了以下函数:\n\n\n**执行函数（子类重载）**\n\n- def splits: Array[Split]    获取数据分片\n- def iterator(split: Split): Iterator[T]   数据分片上的迭代器\n- def preferredLocations(split: Split): Seq[String]  数据分片引用的数据地址\n- def taskStarted(split: Split, slot: SlaveOffer) 任务是否启动\n\n\n**Transform算子**\n\n* def map(f: T => U):MappedRDD\n* def filter(f: T => Boolean):FilteredRDD\n* def aggregateSplit():SplitRDD\n* def cache():CachedRDD\n* def def sample(withReplacement: Boolean, frac: Double,seed: Int):SampledRDD\n* def flatMap(f: T => Traversable[U]):FlatMappedRDD\n\n\n**Action算子**\n\n* def foreach(f: T => Unit):Unit\n* def collect(): Array[T]\n* def toArray(): Array[T]\n* def reduce(f: (T, T) => T): T\n* def take(num: Int): Array[T]\n* def first: T\n* def count(): Long\n* def union(other: RDD[T]):UnionRDD\n* def ++(other: RDD[T]):UnionRDD\n* def cartesian(other: RDD[U]):CartesianRDD\n\n\n\n## RDD类体系\n\n\n\nRDD分为两大类，一类根据外部数据生成，是RDD的起点，在alpha-0.1版本中只有HdfsTextFile 和ParallelArray；另一类是在RDD增加操作产生，如 MappedRDD、FilteredRDD等，该类RDD和transform算子相对应。继承体系如下：\n\n{% asset_img  RDDUml.png %}\n\n{% asset_img  SplitUML.png %}\n\nalpha-0.1中实现的RDD有：\n\n* HdfsTextFile(sc: SparkContext, path: String)\n* ParallelArray(sc: SparkContext, data: Seq[T], numSlices: Int)\n* MappedRDD(prev: RDD[T], f: T => U)\n* FilteredRDD(prev: RDD[T], f: T => Boolean)\n* FlatMappedRDD(prev: RDD[T], f: T => Traversable[U])\n* SplitRDD(prev: RDD[T])\n* SampledRDD(prev: RDD[T], withReplacement: Boolean, frac: Double, seed: Int)\n* CachedRDD(prev: RDD[T])\n* UnionRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[T])\n* CartesianRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[U])\n\n\n\n## 任务调度\n\n如上所述，Action算子会产生任务，并触发任务的提交。下面我们以foreach为例，追踪任务调度流程。\n\n\n\n1. 在action算子（foreach）中，对每个分区(split)生成Task（ForeachTask）实例，并调用sc（SparkContext）中的 runTaskObjects函数来执行任务。\n\n```scala\ndef foreach(f: T => Unit) {\n  val cleanF = sc.clean(f)\n  val tasks = splits.map(s => new ForeachTask(this, s, cleanF)).toArray\n  sc.runTaskObjects(tasks)\n}\n```\n\n2、在SparkContext的 runTaskObjects函数中，调用 Scheduler实例的 runTasks函数来执行任务。\n\n```scala\nclass SparkContext(master: String, frameworkName: String) extends Logging {\n\n  private[spark] def runTaskObjects[T: ClassManifest](tasks: Seq[Task[T]])\n      : Array[T] = {\n    logInfo(\"Running \" + tasks.length + \" tasks in parallel\")\n    val start = System.nanoTime\n    val result = scheduler.runTasks(tasks.toArray)\n    logInfo(\"Tasks finished in \" + (System.nanoTime - start) / 1e9 + \" s\")\n    return result\n  }\n}\n```\n\n\n\n## Scheduler与Task类体系\n\n{% asset_img  SchedulerUML.png %}\n\n# SparkContext\n\nSparkContext有两大职责，一方面管理着spark运行所需的环境，在alpha-0.1中主要是 任务调度器Scheduler；另一方面向用户提供了编程API。主要函数如下：\n\n**运行环境**\n\n* scheduler: Scheduler   任务调度器 \n* def runTasks(tasks: Array[() => T]): Array[T]   任务执行函数（由rdd的action算子调用）\n\n**编程API**\n\n* def textFile(path: String) : HdfsTextFile\n* def parallelize(seq: Seq[T], numSlices: Int):ParallelArray[T]\n* def parallelize(seq: Seq[T]):ParallelArray[T]\n* def accumulator():Accumulator   \n* def broadcast(value: T):CentralizedHDFSBroadcast\n\n\n\n{% asset_img  SparkContextUML.png %}\n\n\n\n# 参考文献\n\n* Spark-alpha-0.1源码解读：https://www.jianshu.com/p/795302f94fa1\n* 百度百科：https://baike.baidu.com/item/RDD/5840158\n\n","slug":"spark源码解析alpha-0-1RDD与任务调度","published":1,"updated":"2019-02-21T06:37:24.268Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvne0b3j0001m7z4indi45ea","content":"<p>Spark源码：<a href=\"https://github.com/apache/spark.git\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/spark.git</a> </p>\n<p>版本号：alpha-0.1</p>\n<p>Spark最核心的概念是RDD（分布式弹性数据集）数据模型，在alpha-0.1版本中实现了RDD数据模型及在其上的任务调度系统，另外还实现了Broadcast和Accumulator工具以及SparkContext接口和spark-shell接口，下面对其分别做介绍。</p>\n<h1 id=\"RDD与任务调度\"><a href=\"#RDD与任务调度\" class=\"headerlink\" title=\"RDD与任务调度\"></a>RDD与任务调度</h1><p>​    百度百科对RDD介绍如下：<em>RDD(Resilient Distributed Datasets)，弹性分布式数据集，是分布式内存的一个抽象概念。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，只能通过在其他RDD执行确定的转换操作（如map、join和group by）而创建，然而这些限制使得实现容错的开销很低。​</em></p>\n<p>​        我们可以将RDD看成一个链表，链表的每个节点在上一个节点数据的基础上增加了一些操作而生成。计算最终数据时，只需按照链表上的操作顺序对数据进行计算即可。</p>\n<p>data -&gt;f1(data)-&gt;f2(f1(data))……-&gt;fn(…f1(data)…)</p>\n<p>RDD将数据分成多个split，每个split可以单独形成操作链表，及整个RDD成为了一组链表。</p>\n<p>不同的操作产生不同的RDD即形成了RDD的类体系。</p>\n<h2 id=\"RDD的API\"><a href=\"#RDD的API\" class=\"headerlink\" title=\"RDD的API\"></a>RDD的API</h2><p>RDD的函数可以分为两类，一类是用户接口算子，包括对数据进行操作的transform算子，如map、filter、reduce等和触发任务执行的Action算子如 count、collect、foreach等；另一类是任务执行时需要的函数，如split、iterator等，子类通过复写这些函数来实现不同的子RDD。在alpha-0.1版本中RDD实现了以下函数:</p>\n<p><strong>执行函数（子类重载）</strong></p>\n<ul>\n<li>def splits: Array[Split]    获取数据分片</li>\n<li>def iterator(split: Split): Iterator[T]   数据分片上的迭代器</li>\n<li>def preferredLocations(split: Split): Seq[String]  数据分片引用的数据地址</li>\n<li>def taskStarted(split: Split, slot: SlaveOffer) 任务是否启动</li>\n</ul>\n<p><strong>Transform算子</strong></p>\n<ul>\n<li>def map(f: T =&gt; U):MappedRDD</li>\n<li>def filter(f: T =&gt; Boolean):FilteredRDD</li>\n<li>def aggregateSplit():SplitRDD</li>\n<li>def cache():CachedRDD</li>\n<li>def def sample(withReplacement: Boolean, frac: Double,seed: Int):SampledRDD</li>\n<li>def flatMap(f: T =&gt; Traversable[U]):FlatMappedRDD</li>\n</ul>\n<p><strong>Action算子</strong></p>\n<ul>\n<li>def foreach(f: T =&gt; Unit):Unit</li>\n<li>def collect(): Array[T]</li>\n<li>def toArray(): Array[T]</li>\n<li>def reduce(f: (T, T) =&gt; T): T</li>\n<li>def take(num: Int): Array[T]</li>\n<li>def first: T</li>\n<li>def count(): Long</li>\n<li>def union(other: RDD[T]):UnionRDD</li>\n<li>def ++(other: RDD[T]):UnionRDD</li>\n<li>def cartesian(other: RDD[U]):CartesianRDD</li>\n</ul>\n<h2 id=\"RDD类体系\"><a href=\"#RDD类体系\" class=\"headerlink\" title=\"RDD类体系\"></a>RDD类体系</h2><p>RDD分为两大类，一类根据外部数据生成，是RDD的起点，在alpha-0.1版本中只有HdfsTextFile 和ParallelArray；另一类是在RDD增加操作产生，如 MappedRDD、FilteredRDD等，该类RDD和transform算子相对应。继承体系如下：</p>\n<img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/RDDUml.png\">\n<img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/SplitUML.png\">\n<p>alpha-0.1中实现的RDD有：</p>\n<ul>\n<li>HdfsTextFile(sc: SparkContext, path: String)</li>\n<li>ParallelArray(sc: SparkContext, data: Seq[T], numSlices: Int)</li>\n<li>MappedRDD(prev: RDD[T], f: T =&gt; U)</li>\n<li>FilteredRDD(prev: RDD[T], f: T =&gt; Boolean)</li>\n<li>FlatMappedRDD(prev: RDD[T], f: T =&gt; Traversable[U])</li>\n<li>SplitRDD(prev: RDD[T])</li>\n<li>SampledRDD(prev: RDD[T], withReplacement: Boolean, frac: Double, seed: Int)</li>\n<li>CachedRDD(prev: RDD[T])</li>\n<li>UnionRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[T])</li>\n<li>CartesianRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[U])</li>\n</ul>\n<h2 id=\"任务调度\"><a href=\"#任务调度\" class=\"headerlink\" title=\"任务调度\"></a>任务调度</h2><p>如上所述，Action算子会产生任务，并触发任务的提交。下面我们以foreach为例，追踪任务调度流程。</p>\n<ol>\n<li>在action算子（foreach）中，对每个分区(split)生成Task（ForeachTask）实例，并调用sc（SparkContext）中的 runTaskObjects函数来执行任务。</li>\n</ol>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">foreach</span></span>(f: <span class=\"hljs-type\">T</span> =&gt; <span class=\"hljs-type\">Unit</span>) &#123;<br>  <span class=\"hljs-keyword\">val</span> cleanF = sc.clean(f)<br>  <span class=\"hljs-keyword\">val</span> tasks = splits.map(s =&gt; <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">ForeachTask</span>(<span class=\"hljs-keyword\">this</span>, s, cleanF)).toArray<br>  sc.runTaskObjects(tasks)<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>2、在SparkContext的 runTaskObjects函数中，调用 Scheduler实例的 runTasks函数来执行任务。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SparkContext</span>(<span class=\"hljs-params\">master: <span class=\"hljs-type\">String</span>, frameworkName: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">Logging</span> </span>&#123;<br><br>  <span class=\"hljs-keyword\">private</span>[spark] <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">runTaskObjects</span></span>[<span class=\"hljs-type\">T</span>: <span class=\"hljs-type\">ClassManifest</span>](tasks: <span class=\"hljs-type\">Seq</span>[<span class=\"hljs-type\">Task</span>[<span class=\"hljs-type\">T</span>]])<br>      : <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">T</span>] = &#123;<br>    logInfo(<span class=\"hljs-string\">\"Running \"</span> + tasks.length + <span class=\"hljs-string\">\" tasks in parallel\"</span>)<br>    <span class=\"hljs-keyword\">val</span> start = <span class=\"hljs-type\">System</span>.nanoTime<br>    <span class=\"hljs-keyword\">val</span> result = scheduler.runTasks(tasks.toArray)<br>    logInfo(<span class=\"hljs-string\">\"Tasks finished in \"</span> + (<span class=\"hljs-type\">System</span>.nanoTime - start) / <span class=\"hljs-number\">1e9</span> + <span class=\"hljs-string\">\" s\"</span>)<br>    <span class=\"hljs-keyword\">return</span> result<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"Scheduler与Task类体系\"><a href=\"#Scheduler与Task类体系\" class=\"headerlink\" title=\"Scheduler与Task类体系\"></a>Scheduler与Task类体系</h2><img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/SchedulerUML.png\">\n<h1 id=\"SparkContext\"><a href=\"#SparkContext\" class=\"headerlink\" title=\"SparkContext\"></a>SparkContext</h1><p>SparkContext有两大职责，一方面管理着spark运行所需的环境，在alpha-0.1中主要是 任务调度器Scheduler；另一方面向用户提供了编程API。主要函数如下：</p>\n<p><strong>运行环境</strong></p>\n<ul>\n<li>scheduler: Scheduler   任务调度器 </li>\n<li>def runTasks(tasks: Array[() =&gt; T]): Array[T]   任务执行函数（由rdd的action算子调用）</li>\n</ul>\n<p><strong>编程API</strong></p>\n<ul>\n<li>def textFile(path: String) : HdfsTextFile</li>\n<li>def parallelize(seq: Seq[T], numSlices: Int):ParallelArray[T]</li>\n<li>def parallelize(seq: Seq[T]):ParallelArray[T]</li>\n<li>def accumulator():Accumulator   </li>\n<li>def broadcast(value: T):CentralizedHDFSBroadcast</li>\n</ul>\n<img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/SparkContextUML.png\">\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li>Spark-alpha-0.1源码解读：<a href=\"https://www.jianshu.com/p/795302f94fa1\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/795302f94fa1</a></li>\n<li>百度百科：<a href=\"https://baike.baidu.com/item/RDD/5840158\" target=\"_blank\" rel=\"noopener\">https://baike.baidu.com/item/RDD/5840158</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>Spark源码：<a href=\"https://github.com/apache/spark.git\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/spark.git</a> </p>\n<p>版本号：alpha-0.1</p>\n<p>Spark最核心的概念是RDD（分布式弹性数据集）数据模型，在alpha-0.1版本中实现了RDD数据模型及在其上的任务调度系统，另外还实现了Broadcast和Accumulator工具以及SparkContext接口和spark-shell接口，下面对其分别做介绍。</p>\n<h1 id=\"RDD与任务调度\"><a href=\"#RDD与任务调度\" class=\"headerlink\" title=\"RDD与任务调度\"></a>RDD与任务调度</h1><p>​    百度百科对RDD介绍如下：<em>RDD(Resilient Distributed Datasets)，弹性分布式数据集，是分布式内存的一个抽象概念。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，只能通过在其他RDD执行确定的转换操作（如map、join和group by）而创建，然而这些限制使得实现容错的开销很低。​</em></p>\n<p>​        我们可以将RDD看成一个链表，链表的每个节点在上一个节点数据的基础上增加了一些操作而生成。计算最终数据时，只需按照链表上的操作顺序对数据进行计算即可。</p>\n<p>data -&gt;f1(data)-&gt;f2(f1(data))……-&gt;fn(…f1(data)…)</p>\n<p>RDD将数据分成多个split，每个split可以单独形成操作链表，及整个RDD成为了一组链表。</p>\n<p>不同的操作产生不同的RDD即形成了RDD的类体系。</p>\n<h2 id=\"RDD的API\"><a href=\"#RDD的API\" class=\"headerlink\" title=\"RDD的API\"></a>RDD的API</h2><p>RDD的函数可以分为两类，一类是用户接口算子，包括对数据进行操作的transform算子，如map、filter、reduce等和触发任务执行的Action算子如 count、collect、foreach等；另一类是任务执行时需要的函数，如split、iterator等，子类通过复写这些函数来实现不同的子RDD。在alpha-0.1版本中RDD实现了以下函数:</p>\n<p><strong>执行函数（子类重载）</strong></p>\n<ul>\n<li>def splits: Array[Split]    获取数据分片</li>\n<li>def iterator(split: Split): Iterator[T]   数据分片上的迭代器</li>\n<li>def preferredLocations(split: Split): Seq[String]  数据分片引用的数据地址</li>\n<li>def taskStarted(split: Split, slot: SlaveOffer) 任务是否启动</li>\n</ul>\n<p><strong>Transform算子</strong></p>\n<ul>\n<li>def map(f: T =&gt; U):MappedRDD</li>\n<li>def filter(f: T =&gt; Boolean):FilteredRDD</li>\n<li>def aggregateSplit():SplitRDD</li>\n<li>def cache():CachedRDD</li>\n<li>def def sample(withReplacement: Boolean, frac: Double,seed: Int):SampledRDD</li>\n<li>def flatMap(f: T =&gt; Traversable[U]):FlatMappedRDD</li>\n</ul>\n<p><strong>Action算子</strong></p>\n<ul>\n<li>def foreach(f: T =&gt; Unit):Unit</li>\n<li>def collect(): Array[T]</li>\n<li>def toArray(): Array[T]</li>\n<li>def reduce(f: (T, T) =&gt; T): T</li>\n<li>def take(num: Int): Array[T]</li>\n<li>def first: T</li>\n<li>def count(): Long</li>\n<li>def union(other: RDD[T]):UnionRDD</li>\n<li>def ++(other: RDD[T]):UnionRDD</li>\n<li>def cartesian(other: RDD[U]):CartesianRDD</li>\n</ul>\n<h2 id=\"RDD类体系\"><a href=\"#RDD类体系\" class=\"headerlink\" title=\"RDD类体系\"></a>RDD类体系</h2><p>RDD分为两大类，一类根据外部数据生成，是RDD的起点，在alpha-0.1版本中只有HdfsTextFile 和ParallelArray；另一类是在RDD增加操作产生，如 MappedRDD、FilteredRDD等，该类RDD和transform算子相对应。继承体系如下：</p>\n<img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/RDDUml.png\">\n<img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/SplitUML.png\">\n<p>alpha-0.1中实现的RDD有：</p>\n<ul>\n<li>HdfsTextFile(sc: SparkContext, path: String)</li>\n<li>ParallelArray(sc: SparkContext, data: Seq[T], numSlices: Int)</li>\n<li>MappedRDD(prev: RDD[T], f: T =&gt; U)</li>\n<li>FilteredRDD(prev: RDD[T], f: T =&gt; Boolean)</li>\n<li>FlatMappedRDD(prev: RDD[T], f: T =&gt; Traversable[U])</li>\n<li>SplitRDD(prev: RDD[T])</li>\n<li>SampledRDD(prev: RDD[T], withReplacement: Boolean, frac: Double, seed: Int)</li>\n<li>CachedRDD(prev: RDD[T])</li>\n<li>UnionRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[T])</li>\n<li>CartesianRDD(sc: SparkContext, rdd1: RDD[T], rdd2: RDD[U])</li>\n</ul>\n<h2 id=\"任务调度\"><a href=\"#任务调度\" class=\"headerlink\" title=\"任务调度\"></a>任务调度</h2><p>如上所述，Action算子会产生任务，并触发任务的提交。下面我们以foreach为例，追踪任务调度流程。</p>\n<ol>\n<li>在action算子（foreach）中，对每个分区(split)生成Task（ForeachTask）实例，并调用sc（SparkContext）中的 runTaskObjects函数来执行任务。</li>\n</ol>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">foreach</span></span>(f: <span class=\"hljs-type\">T</span> =&gt; <span class=\"hljs-type\">Unit</span>) &#123;<br>  <span class=\"hljs-keyword\">val</span> cleanF = sc.clean(f)<br>  <span class=\"hljs-keyword\">val</span> tasks = splits.map(s =&gt; <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">ForeachTask</span>(<span class=\"hljs-keyword\">this</span>, s, cleanF)).toArray<br>  sc.runTaskObjects(tasks)<br>&#125;<br></code></pre></td></tr></table></figure>\n<p>2、在SparkContext的 runTaskObjects函数中，调用 Scheduler实例的 runTasks函数来执行任务。</p>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SparkContext</span>(<span class=\"hljs-params\">master: <span class=\"hljs-type\">String</span>, frameworkName: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">Logging</span> </span>&#123;<br><br>  <span class=\"hljs-keyword\">private</span>[spark] <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">runTaskObjects</span></span>[<span class=\"hljs-type\">T</span>: <span class=\"hljs-type\">ClassManifest</span>](tasks: <span class=\"hljs-type\">Seq</span>[<span class=\"hljs-type\">Task</span>[<span class=\"hljs-type\">T</span>]])<br>      : <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">T</span>] = &#123;<br>    logInfo(<span class=\"hljs-string\">\"Running \"</span> + tasks.length + <span class=\"hljs-string\">\" tasks in parallel\"</span>)<br>    <span class=\"hljs-keyword\">val</span> start = <span class=\"hljs-type\">System</span>.nanoTime<br>    <span class=\"hljs-keyword\">val</span> result = scheduler.runTasks(tasks.toArray)<br>    logInfo(<span class=\"hljs-string\">\"Tasks finished in \"</span> + (<span class=\"hljs-type\">System</span>.nanoTime - start) / <span class=\"hljs-number\">1e9</span> + <span class=\"hljs-string\">\" s\"</span>)<br>    <span class=\"hljs-keyword\">return</span> result<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h2 id=\"Scheduler与Task类体系\"><a href=\"#Scheduler与Task类体系\" class=\"headerlink\" title=\"Scheduler与Task类体系\"></a>Scheduler与Task类体系</h2><img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/SchedulerUML.png\">\n<h1 id=\"SparkContext\"><a href=\"#SparkContext\" class=\"headerlink\" title=\"SparkContext\"></a>SparkContext</h1><p>SparkContext有两大职责，一方面管理着spark运行所需的环境，在alpha-0.1中主要是 任务调度器Scheduler；另一方面向用户提供了编程API。主要函数如下：</p>\n<p><strong>运行环境</strong></p>\n<ul>\n<li>scheduler: Scheduler   任务调度器 </li>\n<li>def runTasks(tasks: Array[() =&gt; T]): Array[T]   任务执行函数（由rdd的action算子调用）</li>\n</ul>\n<p><strong>编程API</strong></p>\n<ul>\n<li>def textFile(path: String) : HdfsTextFile</li>\n<li>def parallelize(seq: Seq[T], numSlices: Int):ParallelArray[T]</li>\n<li>def parallelize(seq: Seq[T]):ParallelArray[T]</li>\n<li>def accumulator():Accumulator   </li>\n<li>def broadcast(value: T):CentralizedHDFSBroadcast</li>\n</ul>\n<img src=\"/2019/02/15/spark源码解析alpha-0-1RDD与任务调度/SparkContextUML.png\">\n<h1 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h1><ul>\n<li>Spark-alpha-0.1源码解读：<a href=\"https://www.jianshu.com/p/795302f94fa1\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/795302f94fa1</a></li>\n<li>百度百科：<a href=\"https://baike.baidu.com/item/RDD/5840158\" target=\"_blank\" rel=\"noopener\">https://baike.baidu.com/item/RDD/5840158</a></li>\n</ul>\n"},{"title":"kylin启动过程","_content":"\n    #To save all these troubles, we use hbase runjar to start tomcat.\n    #In this way we no longer need to explicitly configure hadoop/hbase related classpath for tomcat,\n    #hbase command will do all the dirty tasks for us:\n\n\n     hbase\n     org.apache.hadoop.util.RunJar\n     ${tomcat_root}/bin/bootstrap.jar  org.apache.catalina.startup.Bootstrap start\n\n","source":"_drafts/kylin启动过程.md","raw":"---\ntitle: kylin启动过程\ntags:\n---\n\n    #To save all these troubles, we use hbase runjar to start tomcat.\n    #In this way we no longer need to explicitly configure hadoop/hbase related classpath for tomcat,\n    #hbase command will do all the dirty tasks for us:\n\n\n     hbase\n     org.apache.hadoop.util.RunJar\n     ${tomcat_root}/bin/bootstrap.jar  org.apache.catalina.startup.Bootstrap start\n\n","slug":"kylin启动过程","published":0,"date":"2018-12-25T10:18:46.207Z","updated":"2018-12-26T06:34:46.411Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvne0b3r0003m7z4v7co2c5j","content":"<pre><code>#To save all these troubles, we use hbase runjar to start tomcat.\n#In this way we no longer need to explicitly configure hadoop/hbase related classpath for tomcat,\n#hbase command will do all the dirty tasks for us:\n\n\n hbase\n org.apache.hadoop.util.RunJar\n ${tomcat_root}/bin/bootstrap.jar  org.apache.catalina.startup.Bootstrap start\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<pre><code>#To save all these troubles, we use hbase runjar to start tomcat.\n#In this way we no longer need to explicitly configure hadoop/hbase related classpath for tomcat,\n#hbase command will do all the dirty tasks for us:\n\n\n hbase\n org.apache.hadoop.util.RunJar\n ${tomcat_root}/bin/bootstrap.jar  org.apache.catalina.startup.Bootstrap start\n</code></pre>"},{"title":"kylin支持的聚合函数","_content":"\n","source":"_drafts/kylin支持的聚合函数.md","raw":"---\ntitle: kylin支持的聚合函数\ntags:\n---\n\n","slug":"kylin支持的聚合函数","published":0,"date":"2018-12-25T08:15:42.505Z","updated":"2018-12-25T08:18:49.071Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvne0b3u0004m7z44sy48534","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"初探Flink之编程模型","date":"2019-05-13T02:03:53.000Z","_content":"\n我们从官网文档开始，一窥Flink初貌。(https://ci.apache.org/projects/flink/flink-docs-release-1.8/)\n\n在学习Flink时，我们以和spark的对比，作为很重要的一条线来贯穿始终，通过对比两者的异同，来进一步理解分布式计算中需要解决的问题，及其解决方案。\n\nFlink官网对其定义如下：\t\t\n\nApache Flink is an open source platform for distributed stream and batch data processing.Flink’s core is a streaming dataflow engine that provides data distribution, communication, and fault tolerance for distributed computations over data streams. Flink builds batch processing on top of the streaming engine, overlaying native iteration support, managed memory, and program optimization.\n\n\n\n从上述定义，我们了解到：\n\n1. Flink是一个开源的流处理和批处理平台；\n2. Flink的核心是流处理引擎；\n3. 批处理功能建立在流引擎之上。\n\n\n\n**与Spark异同**\n\n1. 从功能定位来看，两者非常非常相似，都同时支持流计算和批处理；\n2. Spark 把流处理建立在批处理引擎上，流处理是微批处理计算；\n3. Flink把批处理建立在流处理引擎上，批处理是一个有限流。\n\n\n\n官网文档给出了学习路径建议：\n\n1. 基础概念学习 ([Dataflow Programming Model](https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/programming-model.html)  和 [Distributed Runtime Environment](https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/runtime.html). )\n2. 学习导引\n   - [Implement and run a DataStream application](https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/datastream_api.html)\n   - [Setup a local Flink cluster](https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/local_setup.html)\n\n下面我们就按照这个顺利来逐步深入，一窥究竟。\n\n## 整体架构分层\n\n\n\nFlink 将整个架构分成如下四层：\n\n* Stateful Stream Processing:  定义了最核心的任务模型和最底层处理函数；\n* Core APIs : 定义了批处理和流处理相关的API；\n* Table API：定义了一个更高层的面向Table 抽象的API，即数据有schema ，定义了Table上常用的各种操作(select，filter，group by)等；\n* SQL ：SQL接口。\n\n\n\n![Programming levels of abstraction](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/levels_of_abstraction.svg)\n\n\n\n与Spark异同\n\n1. 整体结构两者非常类似；\n\n2. Flink中 流处理和批处理更加一致）;\n\n   * Spark中 基于RDD(最核心模型、批处理)创建了DataFrame（Table API）和Streaming(流处理)又分别在DataFrame和Streaming之上创建了 spark sql 和 struct streaming接口\n\n   * 而从上图可以很容易的看出flink对待流处理和批处理的一致性，ps: 阿里在致力于让两者更加一致。\n\n3. Flink各层概念及定位更加清晰，可能更两者的发展有关，Spark是慢慢生长出来的，而Flink是阿里在其幼小时（2015年），大刀阔斧的改出来的，这个时期Spark已经是1.4版本（Spark和Flink 各 release版本见附录），其批处理、流处理及DataFrame已经比较完善。\n\nps: 只是初步印象，待深入研究结论未必如此。\n\n\n\n## 编程模型\n\n![A DataStream program, and its dataflow.](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/program_dataflow.svg)\n\n\n\n![A parallel dataflow](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/parallel_dataflow.svg)\n\n\n\n\n\nFlink的编程模型，主要是 **Stream** 及其上的 **Transformations**， 其中Stream 定义了分布式数据模型，Transformations 定义了 不同的Stream 所支持的各种操作（从上图也可以看出与Spark代码惊人的相似）。  \n\n**与Spark异同**\n\n1. 两者及其相似，核心都是分布式数据模型，及其上的操作组成；\n\n2. Spark 将操作分为 Transform(Lazy 操作，定义了数据模型的各种变换) 和 Action(真正触发 Job的执行)；\n\n3. 正如两者的核心理念不同，Spark基于批处理RDD模型，Flink 基于流处理 Stream模型。\n\n4. 执行时都会将代码生成 DAG（**directed acyclic graphs**）；\n\n5. 区分不同的操作依赖上游一个分区或多个分区的情况（Spark中窄依赖和宽依赖，Flink中**One-to-one**和**Redistributing**）。\n\n    \n\n   思考：两者一个以流计算为核心，一个以批处理为核心，会是两者不可逾越的鸿沟吗？还是最终会渐渐一致？ \n\n\n\n## 其他概念\n\n### Windows\n\n\n\n和批处理不同的是，流处理面对的数据是无限的，所以不能对一个流的所有数据进行处理，因此需要将一个无限流划分出一些有限的窗口，对每个窗口内的数据进行计算。\n\n![Time- and Count Windows](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/windows.svg)\n\n* 可以按照时间(如每5秒)也可以按照数据量(如每500条数据)来划分窗口；\n* Flink 定义了多种窗口类型以应对不同的业务需求，如 *tumbling windows* (无重叠), *sliding windows* (窗口间有重叠), and *session windows* (定义不活跃时间间隔来划分窗口).\n\n\n\n### Time\n\n![Event Time, Ingestion Time, and Processing Time](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/event_ingestion_processing_time.svg)\n\n\n\nFlink中可以按照以下三种时间来进行数据对齐处理：\n\n* Event Time： 事件时间，通常是日志中打的行为发生时的时间戳；\n* Ingestion Time： 事件进入Flink 的时间；\n* Processing Time： Flink任务执行时的本地时间。\n\n\n\n### Stateful Operations\n\n有些业务场景中，需要对多条Event记录进行汇总统计，而不是逐条记录单独处理。这种情况下的操作成为 Stateful(有状态)的。\n\n在实现上，其实Flink维护了一个类似Key-Value的结构来记录各state。\n\n\n\n![State and Partitioning](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/state_partitioning.svg)\n\n\n\n### Checkpoints 容错\n\nFlink 使用checkpoint和回放（stream replay）机制来做容错机制。\n\n所谓checkpoint即定时的将数据的镜像进行持久化存储。当遇到故障时，从镜像点开始从新计算数据。\n\n需要在checkpoint 保存周期和 故障时数据恢复时间之间做一个权衡。\n\n\n\n### 批处理\n\nFlink 将批处理当成一种特殊的流(有限的流)，但Flink也有针对批处理的离线特性做一些优化：\n\n* 批处理不适用 checkpoint 进行容错，遇到故障时从头（对应分区）计算数据；\n* Stateful操作使用 in-memory/out-of-core数据结构，而不是使用 k-v 索引；(需要进一步研究)\n* 有一些批处理独有的异步API。\n\n## 附录一：Spark各版本发布时间\n\n| Version | Original release date | Latest version |                         Release date                         |\n| :-----: | :-------------------: | :------------: | :----------------------------------------------------------: |\n|   0.5   |      2012-06-12       |     0.5.1      |                          2012-10-07                          |\n|   0.6   |      2012-10-14       |     0.6.2      | 2013-02-07[[36\\]](https://en.wikipedia.org/wiki/Apache_Spark#cite_note-37) |\n|   0.7   |      2013-02-27       |     0.7.3      |                          2013-07-16                          |\n|   0.8   |      2013-09-25       |     0.8.1      |                          2013-12-19                          |\n|   0.9   |      2014-02-02       |     0.9.2      |                          2014-07-23                          |\n|   1.0   |      2014-05-26       |     1.0.2      |                          2014-08-05                          |\n|   1.1   |      2014-09-11       |     1.1.1      |                          2014-11-26                          |\n|   1.2   |      2014-12-18       |     1.2.2      |                          2015-04-17                          |\n|   1.3   |      2015-03-13       |     1.3.1      |                          2015-04-17                          |\n|   1.4   |      2015-06-11       |     1.4.1      |                          2015-07-15                          |\n|   1.5   |      2015-09-09       |     1.5.2      |                          2015-11-09                          |\n|   1.6   |      2016-01-04       |     1.6.3      |                          2016-11-07                          |\n\n\n\n\n\n## 附录二： Flink 各版本发布时间\n\n| Version | Original release date | Latest version | Release date |\n| :-----: | :-------------------: | :------------: | :----------: |\n|   0.9   |      2015-06-24       |     0.9.1      |  2015-09-01  |\n|  0.10   |      2015-11-16       |     0.10.2     |  2016-02-11  |\n|   1.0   |      2016-03-08       |     1.0.3      |  2016-05-11  |\n|   1.1   |      2016-08-08       |     1.1.5      |  2017-03-22  |\n|   1.2   |      2017-02-06       |     1.2.1      |  2017-04-26  |\n|   1.3   |      2017-06-01       |     1.3.3      |  2018-03-15  |\n|   1.4   |      2017-12-12       |     1.4.2      |  2018-03-08  |\n|   1.5   |      2018-05-25       |     1.5.6      |  2018-12-26  |\n|   1.6   |      2018-08-08       |     1.6.3      |  2018-12-22  |\n|   1.7   |      2018-11-30       |     1.7.2      |  2019-02-15  |\n| **1.8** |      2019-04-09       |     1.8.0      |  2019-04-09  |\n\n","source":"_posts/Hello-Flink.md","raw":"---\ntitle: 初探Flink之编程模型\ndate: 2019-05-13 10:03:53\ntags: flink\n\n---\n\n我们从官网文档开始，一窥Flink初貌。(https://ci.apache.org/projects/flink/flink-docs-release-1.8/)\n\n在学习Flink时，我们以和spark的对比，作为很重要的一条线来贯穿始终，通过对比两者的异同，来进一步理解分布式计算中需要解决的问题，及其解决方案。\n\nFlink官网对其定义如下：\t\t\n\nApache Flink is an open source platform for distributed stream and batch data processing.Flink’s core is a streaming dataflow engine that provides data distribution, communication, and fault tolerance for distributed computations over data streams. Flink builds batch processing on top of the streaming engine, overlaying native iteration support, managed memory, and program optimization.\n\n\n\n从上述定义，我们了解到：\n\n1. Flink是一个开源的流处理和批处理平台；\n2. Flink的核心是流处理引擎；\n3. 批处理功能建立在流引擎之上。\n\n\n\n**与Spark异同**\n\n1. 从功能定位来看，两者非常非常相似，都同时支持流计算和批处理；\n2. Spark 把流处理建立在批处理引擎上，流处理是微批处理计算；\n3. Flink把批处理建立在流处理引擎上，批处理是一个有限流。\n\n\n\n官网文档给出了学习路径建议：\n\n1. 基础概念学习 ([Dataflow Programming Model](https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/programming-model.html)  和 [Distributed Runtime Environment](https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/runtime.html). )\n2. 学习导引\n   - [Implement and run a DataStream application](https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/datastream_api.html)\n   - [Setup a local Flink cluster](https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/local_setup.html)\n\n下面我们就按照这个顺利来逐步深入，一窥究竟。\n\n## 整体架构分层\n\n\n\nFlink 将整个架构分成如下四层：\n\n* Stateful Stream Processing:  定义了最核心的任务模型和最底层处理函数；\n* Core APIs : 定义了批处理和流处理相关的API；\n* Table API：定义了一个更高层的面向Table 抽象的API，即数据有schema ，定义了Table上常用的各种操作(select，filter，group by)等；\n* SQL ：SQL接口。\n\n\n\n![Programming levels of abstraction](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/levels_of_abstraction.svg)\n\n\n\n与Spark异同\n\n1. 整体结构两者非常类似；\n\n2. Flink中 流处理和批处理更加一致）;\n\n   * Spark中 基于RDD(最核心模型、批处理)创建了DataFrame（Table API）和Streaming(流处理)又分别在DataFrame和Streaming之上创建了 spark sql 和 struct streaming接口\n\n   * 而从上图可以很容易的看出flink对待流处理和批处理的一致性，ps: 阿里在致力于让两者更加一致。\n\n3. Flink各层概念及定位更加清晰，可能更两者的发展有关，Spark是慢慢生长出来的，而Flink是阿里在其幼小时（2015年），大刀阔斧的改出来的，这个时期Spark已经是1.4版本（Spark和Flink 各 release版本见附录），其批处理、流处理及DataFrame已经比较完善。\n\nps: 只是初步印象，待深入研究结论未必如此。\n\n\n\n## 编程模型\n\n![A DataStream program, and its dataflow.](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/program_dataflow.svg)\n\n\n\n![A parallel dataflow](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/parallel_dataflow.svg)\n\n\n\n\n\nFlink的编程模型，主要是 **Stream** 及其上的 **Transformations**， 其中Stream 定义了分布式数据模型，Transformations 定义了 不同的Stream 所支持的各种操作（从上图也可以看出与Spark代码惊人的相似）。  \n\n**与Spark异同**\n\n1. 两者及其相似，核心都是分布式数据模型，及其上的操作组成；\n\n2. Spark 将操作分为 Transform(Lazy 操作，定义了数据模型的各种变换) 和 Action(真正触发 Job的执行)；\n\n3. 正如两者的核心理念不同，Spark基于批处理RDD模型，Flink 基于流处理 Stream模型。\n\n4. 执行时都会将代码生成 DAG（**directed acyclic graphs**）；\n\n5. 区分不同的操作依赖上游一个分区或多个分区的情况（Spark中窄依赖和宽依赖，Flink中**One-to-one**和**Redistributing**）。\n\n    \n\n   思考：两者一个以流计算为核心，一个以批处理为核心，会是两者不可逾越的鸿沟吗？还是最终会渐渐一致？ \n\n\n\n## 其他概念\n\n### Windows\n\n\n\n和批处理不同的是，流处理面对的数据是无限的，所以不能对一个流的所有数据进行处理，因此需要将一个无限流划分出一些有限的窗口，对每个窗口内的数据进行计算。\n\n![Time- and Count Windows](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/windows.svg)\n\n* 可以按照时间(如每5秒)也可以按照数据量(如每500条数据)来划分窗口；\n* Flink 定义了多种窗口类型以应对不同的业务需求，如 *tumbling windows* (无重叠), *sliding windows* (窗口间有重叠), and *session windows* (定义不活跃时间间隔来划分窗口).\n\n\n\n### Time\n\n![Event Time, Ingestion Time, and Processing Time](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/event_ingestion_processing_time.svg)\n\n\n\nFlink中可以按照以下三种时间来进行数据对齐处理：\n\n* Event Time： 事件时间，通常是日志中打的行为发生时的时间戳；\n* Ingestion Time： 事件进入Flink 的时间；\n* Processing Time： Flink任务执行时的本地时间。\n\n\n\n### Stateful Operations\n\n有些业务场景中，需要对多条Event记录进行汇总统计，而不是逐条记录单独处理。这种情况下的操作成为 Stateful(有状态)的。\n\n在实现上，其实Flink维护了一个类似Key-Value的结构来记录各state。\n\n\n\n![State and Partitioning](https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/state_partitioning.svg)\n\n\n\n### Checkpoints 容错\n\nFlink 使用checkpoint和回放（stream replay）机制来做容错机制。\n\n所谓checkpoint即定时的将数据的镜像进行持久化存储。当遇到故障时，从镜像点开始从新计算数据。\n\n需要在checkpoint 保存周期和 故障时数据恢复时间之间做一个权衡。\n\n\n\n### 批处理\n\nFlink 将批处理当成一种特殊的流(有限的流)，但Flink也有针对批处理的离线特性做一些优化：\n\n* 批处理不适用 checkpoint 进行容错，遇到故障时从头（对应分区）计算数据；\n* Stateful操作使用 in-memory/out-of-core数据结构，而不是使用 k-v 索引；(需要进一步研究)\n* 有一些批处理独有的异步API。\n\n## 附录一：Spark各版本发布时间\n\n| Version | Original release date | Latest version |                         Release date                         |\n| :-----: | :-------------------: | :------------: | :----------------------------------------------------------: |\n|   0.5   |      2012-06-12       |     0.5.1      |                          2012-10-07                          |\n|   0.6   |      2012-10-14       |     0.6.2      | 2013-02-07[[36\\]](https://en.wikipedia.org/wiki/Apache_Spark#cite_note-37) |\n|   0.7   |      2013-02-27       |     0.7.3      |                          2013-07-16                          |\n|   0.8   |      2013-09-25       |     0.8.1      |                          2013-12-19                          |\n|   0.9   |      2014-02-02       |     0.9.2      |                          2014-07-23                          |\n|   1.0   |      2014-05-26       |     1.0.2      |                          2014-08-05                          |\n|   1.1   |      2014-09-11       |     1.1.1      |                          2014-11-26                          |\n|   1.2   |      2014-12-18       |     1.2.2      |                          2015-04-17                          |\n|   1.3   |      2015-03-13       |     1.3.1      |                          2015-04-17                          |\n|   1.4   |      2015-06-11       |     1.4.1      |                          2015-07-15                          |\n|   1.5   |      2015-09-09       |     1.5.2      |                          2015-11-09                          |\n|   1.6   |      2016-01-04       |     1.6.3      |                          2016-11-07                          |\n\n\n\n\n\n## 附录二： Flink 各版本发布时间\n\n| Version | Original release date | Latest version | Release date |\n| :-----: | :-------------------: | :------------: | :----------: |\n|   0.9   |      2015-06-24       |     0.9.1      |  2015-09-01  |\n|  0.10   |      2015-11-16       |     0.10.2     |  2016-02-11  |\n|   1.0   |      2016-03-08       |     1.0.3      |  2016-05-11  |\n|   1.1   |      2016-08-08       |     1.1.5      |  2017-03-22  |\n|   1.2   |      2017-02-06       |     1.2.1      |  2017-04-26  |\n|   1.3   |      2017-06-01       |     1.3.3      |  2018-03-15  |\n|   1.4   |      2017-12-12       |     1.4.2      |  2018-03-08  |\n|   1.5   |      2018-05-25       |     1.5.6      |  2018-12-26  |\n|   1.6   |      2018-08-08       |     1.6.3      |  2018-12-22  |\n|   1.7   |      2018-11-30       |     1.7.2      |  2019-02-15  |\n| **1.8** |      2019-04-09       |     1.8.0      |  2019-04-09  |\n\n","slug":"Hello-Flink","published":1,"updated":"2019-05-14T05:44:20.290Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvne0b4c0008m7z4tv239dyf","content":"<p>我们从官网文档开始，一窥Flink初貌。(<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/\" target=\"_blank\" rel=\"noopener\">https://ci.apache.org/projects/flink/flink-docs-release-1.8/</a>)</p>\n<p>在学习Flink时，我们以和spark的对比，作为很重要的一条线来贯穿始终，通过对比两者的异同，来进一步理解分布式计算中需要解决的问题，及其解决方案。</p>\n<p>Flink官网对其定义如下：        </p>\n<p>Apache Flink is an open source platform for distributed stream and batch data processing.Flink’s core is a streaming dataflow engine that provides data distribution, communication, and fault tolerance for distributed computations over data streams. Flink builds batch processing on top of the streaming engine, overlaying native iteration support, managed memory, and program optimization.</p>\n<p>从上述定义，我们了解到：</p>\n<ol>\n<li>Flink是一个开源的流处理和批处理平台；</li>\n<li>Flink的核心是流处理引擎；</li>\n<li>批处理功能建立在流引擎之上。</li>\n</ol>\n<p><strong>与Spark异同</strong></p>\n<ol>\n<li>从功能定位来看，两者非常非常相似，都同时支持流计算和批处理；</li>\n<li>Spark 把流处理建立在批处理引擎上，流处理是微批处理计算；</li>\n<li>Flink把批处理建立在流处理引擎上，批处理是一个有限流。</li>\n</ol>\n<p>官网文档给出了学习路径建议：</p>\n<ol>\n<li>基础概念学习 (<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/programming-model.html\" target=\"_blank\" rel=\"noopener\">Dataflow Programming Model</a>  和 <a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/runtime.html\" target=\"_blank\" rel=\"noopener\">Distributed Runtime Environment</a>. )</li>\n<li>学习导引<ul>\n<li><a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/datastream_api.html\" target=\"_blank\" rel=\"noopener\">Implement and run a DataStream application</a></li>\n<li><a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/local_setup.html\" target=\"_blank\" rel=\"noopener\">Setup a local Flink cluster</a></li>\n</ul>\n</li>\n</ol>\n<p>下面我们就按照这个顺利来逐步深入，一窥究竟。</p>\n<h2 id=\"整体架构分层\"><a href=\"#整体架构分层\" class=\"headerlink\" title=\"整体架构分层\"></a>整体架构分层</h2><p>Flink 将整个架构分成如下四层：</p>\n<ul>\n<li>Stateful Stream Processing:  定义了最核心的任务模型和最底层处理函数；</li>\n<li>Core APIs : 定义了批处理和流处理相关的API；</li>\n<li>Table API：定义了一个更高层的面向Table 抽象的API，即数据有schema ，定义了Table上常用的各种操作(select，filter，group by)等；</li>\n<li>SQL ：SQL接口。</li>\n</ul>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/levels_of_abstraction.svg\" alt=\"Programming levels of abstraction\"></p>\n<p>与Spark异同</p>\n<ol>\n<li><p>整体结构两者非常类似；</p>\n</li>\n<li><p>Flink中 流处理和批处理更加一致）;</p>\n<ul>\n<li><p>Spark中 基于RDD(最核心模型、批处理)创建了DataFrame（Table API）和Streaming(流处理)又分别在DataFrame和Streaming之上创建了 spark sql 和 struct streaming接口</p>\n</li>\n<li><p>而从上图可以很容易的看出flink对待流处理和批处理的一致性，ps: 阿里在致力于让两者更加一致。</p>\n</li>\n</ul>\n</li>\n<li><p>Flink各层概念及定位更加清晰，可能更两者的发展有关，Spark是慢慢生长出来的，而Flink是阿里在其幼小时（2015年），大刀阔斧的改出来的，这个时期Spark已经是1.4版本（Spark和Flink 各 release版本见附录），其批处理、流处理及DataFrame已经比较完善。</p>\n</li>\n</ol>\n<p>ps: 只是初步印象，待深入研究结论未必如此。</p>\n<h2 id=\"编程模型\"><a href=\"#编程模型\" class=\"headerlink\" title=\"编程模型\"></a>编程模型</h2><p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/program_dataflow.svg\" alt=\"A DataStream program, and its dataflow.\"></p>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/parallel_dataflow.svg\" alt=\"A parallel dataflow\"></p>\n<p>Flink的编程模型，主要是 <strong>Stream</strong> 及其上的 <strong>Transformations</strong>， 其中Stream 定义了分布式数据模型，Transformations 定义了 不同的Stream 所支持的各种操作（从上图也可以看出与Spark代码惊人的相似）。  </p>\n<p><strong>与Spark异同</strong></p>\n<ol>\n<li><p>两者及其相似，核心都是分布式数据模型，及其上的操作组成；</p>\n</li>\n<li><p>Spark 将操作分为 Transform(Lazy 操作，定义了数据模型的各种变换) 和 Action(真正触发 Job的执行)；</p>\n</li>\n<li><p>正如两者的核心理念不同，Spark基于批处理RDD模型，Flink 基于流处理 Stream模型。</p>\n</li>\n<li><p>执行时都会将代码生成 DAG（<strong>directed acyclic graphs</strong>）；</p>\n</li>\n<li><p>区分不同的操作依赖上游一个分区或多个分区的情况（Spark中窄依赖和宽依赖，Flink中<strong>One-to-one</strong>和<strong>Redistributing</strong>）。</p>\n</li>\n</ol>\n<p>   思考：两者一个以流计算为核心，一个以批处理为核心，会是两者不可逾越的鸿沟吗？还是最终会渐渐一致？ </p>\n<h2 id=\"其他概念\"><a href=\"#其他概念\" class=\"headerlink\" title=\"其他概念\"></a>其他概念</h2><h3 id=\"Windows\"><a href=\"#Windows\" class=\"headerlink\" title=\"Windows\"></a>Windows</h3><p>和批处理不同的是，流处理面对的数据是无限的，所以不能对一个流的所有数据进行处理，因此需要将一个无限流划分出一些有限的窗口，对每个窗口内的数据进行计算。</p>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/windows.svg\" alt=\"Time- and Count Windows\"></p>\n<ul>\n<li>可以按照时间(如每5秒)也可以按照数据量(如每500条数据)来划分窗口；</li>\n<li>Flink 定义了多种窗口类型以应对不同的业务需求，如 <em>tumbling windows</em> (无重叠), <em>sliding windows</em> (窗口间有重叠), and <em>session windows</em> (定义不活跃时间间隔来划分窗口).</li>\n</ul>\n<h3 id=\"Time\"><a href=\"#Time\" class=\"headerlink\" title=\"Time\"></a>Time</h3><p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/event_ingestion_processing_time.svg\" alt=\"Event Time, Ingestion Time, and Processing Time\"></p>\n<p>Flink中可以按照以下三种时间来进行数据对齐处理：</p>\n<ul>\n<li>Event Time： 事件时间，通常是日志中打的行为发生时的时间戳；</li>\n<li>Ingestion Time： 事件进入Flink 的时间；</li>\n<li>Processing Time： Flink任务执行时的本地时间。</li>\n</ul>\n<h3 id=\"Stateful-Operations\"><a href=\"#Stateful-Operations\" class=\"headerlink\" title=\"Stateful Operations\"></a>Stateful Operations</h3><p>有些业务场景中，需要对多条Event记录进行汇总统计，而不是逐条记录单独处理。这种情况下的操作成为 Stateful(有状态)的。</p>\n<p>在实现上，其实Flink维护了一个类似Key-Value的结构来记录各state。</p>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/state_partitioning.svg\" alt=\"State and Partitioning\"></p>\n<h3 id=\"Checkpoints-容错\"><a href=\"#Checkpoints-容错\" class=\"headerlink\" title=\"Checkpoints 容错\"></a>Checkpoints 容错</h3><p>Flink 使用checkpoint和回放（stream replay）机制来做容错机制。</p>\n<p>所谓checkpoint即定时的将数据的镜像进行持久化存储。当遇到故障时，从镜像点开始从新计算数据。</p>\n<p>需要在checkpoint 保存周期和 故障时数据恢复时间之间做一个权衡。</p>\n<h3 id=\"批处理\"><a href=\"#批处理\" class=\"headerlink\" title=\"批处理\"></a>批处理</h3><p>Flink 将批处理当成一种特殊的流(有限的流)，但Flink也有针对批处理的离线特性做一些优化：</p>\n<ul>\n<li>批处理不适用 checkpoint 进行容错，遇到故障时从头（对应分区）计算数据；</li>\n<li>Stateful操作使用 in-memory/out-of-core数据结构，而不是使用 k-v 索引；(需要进一步研究)</li>\n<li>有一些批处理独有的异步API。</li>\n</ul>\n<h2 id=\"附录一：Spark各版本发布时间\"><a href=\"#附录一：Spark各版本发布时间\" class=\"headerlink\" title=\"附录一：Spark各版本发布时间\"></a>附录一：Spark各版本发布时间</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Version</th>\n<th style=\"text-align:center\">Original release date</th>\n<th style=\"text-align:center\">Latest version</th>\n<th style=\"text-align:center\">Release date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0.5</td>\n<td style=\"text-align:center\">2012-06-12</td>\n<td style=\"text-align:center\">0.5.1</td>\n<td style=\"text-align:center\">2012-10-07</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.6</td>\n<td style=\"text-align:center\">2012-10-14</td>\n<td style=\"text-align:center\">0.6.2</td>\n<td style=\"text-align:center\">2013-02-07<a href=\"https://en.wikipedia.org/wiki/Apache_Spark#cite_note-37\" target=\"_blank\" rel=\"noopener\">[36]</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.7</td>\n<td style=\"text-align:center\">2013-02-27</td>\n<td style=\"text-align:center\">0.7.3</td>\n<td style=\"text-align:center\">2013-07-16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.8</td>\n<td style=\"text-align:center\">2013-09-25</td>\n<td style=\"text-align:center\">0.8.1</td>\n<td style=\"text-align:center\">2013-12-19</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.9</td>\n<td style=\"text-align:center\">2014-02-02</td>\n<td style=\"text-align:center\">0.9.2</td>\n<td style=\"text-align:center\">2014-07-23</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.0</td>\n<td style=\"text-align:center\">2014-05-26</td>\n<td style=\"text-align:center\">1.0.2</td>\n<td style=\"text-align:center\">2014-08-05</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.1</td>\n<td style=\"text-align:center\">2014-09-11</td>\n<td style=\"text-align:center\">1.1.1</td>\n<td style=\"text-align:center\">2014-11-26</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.2</td>\n<td style=\"text-align:center\">2014-12-18</td>\n<td style=\"text-align:center\">1.2.2</td>\n<td style=\"text-align:center\">2015-04-17</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.3</td>\n<td style=\"text-align:center\">2015-03-13</td>\n<td style=\"text-align:center\">1.3.1</td>\n<td style=\"text-align:center\">2015-04-17</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.4</td>\n<td style=\"text-align:center\">2015-06-11</td>\n<td style=\"text-align:center\">1.4.1</td>\n<td style=\"text-align:center\">2015-07-15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.5</td>\n<td style=\"text-align:center\">2015-09-09</td>\n<td style=\"text-align:center\">1.5.2</td>\n<td style=\"text-align:center\">2015-11-09</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.6</td>\n<td style=\"text-align:center\">2016-01-04</td>\n<td style=\"text-align:center\">1.6.3</td>\n<td style=\"text-align:center\">2016-11-07</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"附录二：-Flink-各版本发布时间\"><a href=\"#附录二：-Flink-各版本发布时间\" class=\"headerlink\" title=\"附录二： Flink 各版本发布时间\"></a>附录二： Flink 各版本发布时间</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Version</th>\n<th style=\"text-align:center\">Original release date</th>\n<th style=\"text-align:center\">Latest version</th>\n<th style=\"text-align:center\">Release date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0.9</td>\n<td style=\"text-align:center\">2015-06-24</td>\n<td style=\"text-align:center\">0.9.1</td>\n<td style=\"text-align:center\">2015-09-01</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.10</td>\n<td style=\"text-align:center\">2015-11-16</td>\n<td style=\"text-align:center\">0.10.2</td>\n<td style=\"text-align:center\">2016-02-11</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.0</td>\n<td style=\"text-align:center\">2016-03-08</td>\n<td style=\"text-align:center\">1.0.3</td>\n<td style=\"text-align:center\">2016-05-11</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.1</td>\n<td style=\"text-align:center\">2016-08-08</td>\n<td style=\"text-align:center\">1.1.5</td>\n<td style=\"text-align:center\">2017-03-22</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.2</td>\n<td style=\"text-align:center\">2017-02-06</td>\n<td style=\"text-align:center\">1.2.1</td>\n<td style=\"text-align:center\">2017-04-26</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.3</td>\n<td style=\"text-align:center\">2017-06-01</td>\n<td style=\"text-align:center\">1.3.3</td>\n<td style=\"text-align:center\">2018-03-15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.4</td>\n<td style=\"text-align:center\">2017-12-12</td>\n<td style=\"text-align:center\">1.4.2</td>\n<td style=\"text-align:center\">2018-03-08</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.5</td>\n<td style=\"text-align:center\">2018-05-25</td>\n<td style=\"text-align:center\">1.5.6</td>\n<td style=\"text-align:center\">2018-12-26</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.6</td>\n<td style=\"text-align:center\">2018-08-08</td>\n<td style=\"text-align:center\">1.6.3</td>\n<td style=\"text-align:center\">2018-12-22</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.7</td>\n<td style=\"text-align:center\">2018-11-30</td>\n<td style=\"text-align:center\">1.7.2</td>\n<td style=\"text-align:center\">2019-02-15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>1.8</strong></td>\n<td style=\"text-align:center\">2019-04-09</td>\n<td style=\"text-align:center\">1.8.0</td>\n<td style=\"text-align:center\">2019-04-09</td>\n</tr>\n</tbody>\n</table>\n","site":{"data":{}},"excerpt":"","more":"<p>我们从官网文档开始，一窥Flink初貌。(<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/\" target=\"_blank\" rel=\"noopener\">https://ci.apache.org/projects/flink/flink-docs-release-1.8/</a>)</p>\n<p>在学习Flink时，我们以和spark的对比，作为很重要的一条线来贯穿始终，通过对比两者的异同，来进一步理解分布式计算中需要解决的问题，及其解决方案。</p>\n<p>Flink官网对其定义如下：        </p>\n<p>Apache Flink is an open source platform for distributed stream and batch data processing.Flink’s core is a streaming dataflow engine that provides data distribution, communication, and fault tolerance for distributed computations over data streams. Flink builds batch processing on top of the streaming engine, overlaying native iteration support, managed memory, and program optimization.</p>\n<p>从上述定义，我们了解到：</p>\n<ol>\n<li>Flink是一个开源的流处理和批处理平台；</li>\n<li>Flink的核心是流处理引擎；</li>\n<li>批处理功能建立在流引擎之上。</li>\n</ol>\n<p><strong>与Spark异同</strong></p>\n<ol>\n<li>从功能定位来看，两者非常非常相似，都同时支持流计算和批处理；</li>\n<li>Spark 把流处理建立在批处理引擎上，流处理是微批处理计算；</li>\n<li>Flink把批处理建立在流处理引擎上，批处理是一个有限流。</li>\n</ol>\n<p>官网文档给出了学习路径建议：</p>\n<ol>\n<li>基础概念学习 (<a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/programming-model.html\" target=\"_blank\" rel=\"noopener\">Dataflow Programming Model</a>  和 <a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/concepts/runtime.html\" target=\"_blank\" rel=\"noopener\">Distributed Runtime Environment</a>. )</li>\n<li>学习导引<ul>\n<li><a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/datastream_api.html\" target=\"_blank\" rel=\"noopener\">Implement and run a DataStream application</a></li>\n<li><a href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/local_setup.html\" target=\"_blank\" rel=\"noopener\">Setup a local Flink cluster</a></li>\n</ul>\n</li>\n</ol>\n<p>下面我们就按照这个顺利来逐步深入，一窥究竟。</p>\n<h2 id=\"整体架构分层\"><a href=\"#整体架构分层\" class=\"headerlink\" title=\"整体架构分层\"></a>整体架构分层</h2><p>Flink 将整个架构分成如下四层：</p>\n<ul>\n<li>Stateful Stream Processing:  定义了最核心的任务模型和最底层处理函数；</li>\n<li>Core APIs : 定义了批处理和流处理相关的API；</li>\n<li>Table API：定义了一个更高层的面向Table 抽象的API，即数据有schema ，定义了Table上常用的各种操作(select，filter，group by)等；</li>\n<li>SQL ：SQL接口。</li>\n</ul>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/levels_of_abstraction.svg\" alt=\"Programming levels of abstraction\"></p>\n<p>与Spark异同</p>\n<ol>\n<li><p>整体结构两者非常类似；</p>\n</li>\n<li><p>Flink中 流处理和批处理更加一致）;</p>\n<ul>\n<li><p>Spark中 基于RDD(最核心模型、批处理)创建了DataFrame（Table API）和Streaming(流处理)又分别在DataFrame和Streaming之上创建了 spark sql 和 struct streaming接口</p>\n</li>\n<li><p>而从上图可以很容易的看出flink对待流处理和批处理的一致性，ps: 阿里在致力于让两者更加一致。</p>\n</li>\n</ul>\n</li>\n<li><p>Flink各层概念及定位更加清晰，可能更两者的发展有关，Spark是慢慢生长出来的，而Flink是阿里在其幼小时（2015年），大刀阔斧的改出来的，这个时期Spark已经是1.4版本（Spark和Flink 各 release版本见附录），其批处理、流处理及DataFrame已经比较完善。</p>\n</li>\n</ol>\n<p>ps: 只是初步印象，待深入研究结论未必如此。</p>\n<h2 id=\"编程模型\"><a href=\"#编程模型\" class=\"headerlink\" title=\"编程模型\"></a>编程模型</h2><p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/program_dataflow.svg\" alt=\"A DataStream program, and its dataflow.\"></p>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/parallel_dataflow.svg\" alt=\"A parallel dataflow\"></p>\n<p>Flink的编程模型，主要是 <strong>Stream</strong> 及其上的 <strong>Transformations</strong>， 其中Stream 定义了分布式数据模型，Transformations 定义了 不同的Stream 所支持的各种操作（从上图也可以看出与Spark代码惊人的相似）。  </p>\n<p><strong>与Spark异同</strong></p>\n<ol>\n<li><p>两者及其相似，核心都是分布式数据模型，及其上的操作组成；</p>\n</li>\n<li><p>Spark 将操作分为 Transform(Lazy 操作，定义了数据模型的各种变换) 和 Action(真正触发 Job的执行)；</p>\n</li>\n<li><p>正如两者的核心理念不同，Spark基于批处理RDD模型，Flink 基于流处理 Stream模型。</p>\n</li>\n<li><p>执行时都会将代码生成 DAG（<strong>directed acyclic graphs</strong>）；</p>\n</li>\n<li><p>区分不同的操作依赖上游一个分区或多个分区的情况（Spark中窄依赖和宽依赖，Flink中<strong>One-to-one</strong>和<strong>Redistributing</strong>）。</p>\n</li>\n</ol>\n<p>   思考：两者一个以流计算为核心，一个以批处理为核心，会是两者不可逾越的鸿沟吗？还是最终会渐渐一致？ </p>\n<h2 id=\"其他概念\"><a href=\"#其他概念\" class=\"headerlink\" title=\"其他概念\"></a>其他概念</h2><h3 id=\"Windows\"><a href=\"#Windows\" class=\"headerlink\" title=\"Windows\"></a>Windows</h3><p>和批处理不同的是，流处理面对的数据是无限的，所以不能对一个流的所有数据进行处理，因此需要将一个无限流划分出一些有限的窗口，对每个窗口内的数据进行计算。</p>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/windows.svg\" alt=\"Time- and Count Windows\"></p>\n<ul>\n<li>可以按照时间(如每5秒)也可以按照数据量(如每500条数据)来划分窗口；</li>\n<li>Flink 定义了多种窗口类型以应对不同的业务需求，如 <em>tumbling windows</em> (无重叠), <em>sliding windows</em> (窗口间有重叠), and <em>session windows</em> (定义不活跃时间间隔来划分窗口).</li>\n</ul>\n<h3 id=\"Time\"><a href=\"#Time\" class=\"headerlink\" title=\"Time\"></a>Time</h3><p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/event_ingestion_processing_time.svg\" alt=\"Event Time, Ingestion Time, and Processing Time\"></p>\n<p>Flink中可以按照以下三种时间来进行数据对齐处理：</p>\n<ul>\n<li>Event Time： 事件时间，通常是日志中打的行为发生时的时间戳；</li>\n<li>Ingestion Time： 事件进入Flink 的时间；</li>\n<li>Processing Time： Flink任务执行时的本地时间。</li>\n</ul>\n<h3 id=\"Stateful-Operations\"><a href=\"#Stateful-Operations\" class=\"headerlink\" title=\"Stateful Operations\"></a>Stateful Operations</h3><p>有些业务场景中，需要对多条Event记录进行汇总统计，而不是逐条记录单独处理。这种情况下的操作成为 Stateful(有状态)的。</p>\n<p>在实现上，其实Flink维护了一个类似Key-Value的结构来记录各state。</p>\n<p><img src=\"https://ci.apache.org/projects/flink/flink-docs-release-1.8/fig/state_partitioning.svg\" alt=\"State and Partitioning\"></p>\n<h3 id=\"Checkpoints-容错\"><a href=\"#Checkpoints-容错\" class=\"headerlink\" title=\"Checkpoints 容错\"></a>Checkpoints 容错</h3><p>Flink 使用checkpoint和回放（stream replay）机制来做容错机制。</p>\n<p>所谓checkpoint即定时的将数据的镜像进行持久化存储。当遇到故障时，从镜像点开始从新计算数据。</p>\n<p>需要在checkpoint 保存周期和 故障时数据恢复时间之间做一个权衡。</p>\n<h3 id=\"批处理\"><a href=\"#批处理\" class=\"headerlink\" title=\"批处理\"></a>批处理</h3><p>Flink 将批处理当成一种特殊的流(有限的流)，但Flink也有针对批处理的离线特性做一些优化：</p>\n<ul>\n<li>批处理不适用 checkpoint 进行容错，遇到故障时从头（对应分区）计算数据；</li>\n<li>Stateful操作使用 in-memory/out-of-core数据结构，而不是使用 k-v 索引；(需要进一步研究)</li>\n<li>有一些批处理独有的异步API。</li>\n</ul>\n<h2 id=\"附录一：Spark各版本发布时间\"><a href=\"#附录一：Spark各版本发布时间\" class=\"headerlink\" title=\"附录一：Spark各版本发布时间\"></a>附录一：Spark各版本发布时间</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Version</th>\n<th style=\"text-align:center\">Original release date</th>\n<th style=\"text-align:center\">Latest version</th>\n<th style=\"text-align:center\">Release date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0.5</td>\n<td style=\"text-align:center\">2012-06-12</td>\n<td style=\"text-align:center\">0.5.1</td>\n<td style=\"text-align:center\">2012-10-07</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.6</td>\n<td style=\"text-align:center\">2012-10-14</td>\n<td style=\"text-align:center\">0.6.2</td>\n<td style=\"text-align:center\">2013-02-07<a href=\"https://en.wikipedia.org/wiki/Apache_Spark#cite_note-37\" target=\"_blank\" rel=\"noopener\">[36]</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.7</td>\n<td style=\"text-align:center\">2013-02-27</td>\n<td style=\"text-align:center\">0.7.3</td>\n<td style=\"text-align:center\">2013-07-16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.8</td>\n<td style=\"text-align:center\">2013-09-25</td>\n<td style=\"text-align:center\">0.8.1</td>\n<td style=\"text-align:center\">2013-12-19</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.9</td>\n<td style=\"text-align:center\">2014-02-02</td>\n<td style=\"text-align:center\">0.9.2</td>\n<td style=\"text-align:center\">2014-07-23</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.0</td>\n<td style=\"text-align:center\">2014-05-26</td>\n<td style=\"text-align:center\">1.0.2</td>\n<td style=\"text-align:center\">2014-08-05</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.1</td>\n<td style=\"text-align:center\">2014-09-11</td>\n<td style=\"text-align:center\">1.1.1</td>\n<td style=\"text-align:center\">2014-11-26</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.2</td>\n<td style=\"text-align:center\">2014-12-18</td>\n<td style=\"text-align:center\">1.2.2</td>\n<td style=\"text-align:center\">2015-04-17</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.3</td>\n<td style=\"text-align:center\">2015-03-13</td>\n<td style=\"text-align:center\">1.3.1</td>\n<td style=\"text-align:center\">2015-04-17</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.4</td>\n<td style=\"text-align:center\">2015-06-11</td>\n<td style=\"text-align:center\">1.4.1</td>\n<td style=\"text-align:center\">2015-07-15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.5</td>\n<td style=\"text-align:center\">2015-09-09</td>\n<td style=\"text-align:center\">1.5.2</td>\n<td style=\"text-align:center\">2015-11-09</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.6</td>\n<td style=\"text-align:center\">2016-01-04</td>\n<td style=\"text-align:center\">1.6.3</td>\n<td style=\"text-align:center\">2016-11-07</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"附录二：-Flink-各版本发布时间\"><a href=\"#附录二：-Flink-各版本发布时间\" class=\"headerlink\" title=\"附录二： Flink 各版本发布时间\"></a>附录二： Flink 各版本发布时间</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Version</th>\n<th style=\"text-align:center\">Original release date</th>\n<th style=\"text-align:center\">Latest version</th>\n<th style=\"text-align:center\">Release date</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0.9</td>\n<td style=\"text-align:center\">2015-06-24</td>\n<td style=\"text-align:center\">0.9.1</td>\n<td style=\"text-align:center\">2015-09-01</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">0.10</td>\n<td style=\"text-align:center\">2015-11-16</td>\n<td style=\"text-align:center\">0.10.2</td>\n<td style=\"text-align:center\">2016-02-11</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.0</td>\n<td style=\"text-align:center\">2016-03-08</td>\n<td style=\"text-align:center\">1.0.3</td>\n<td style=\"text-align:center\">2016-05-11</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.1</td>\n<td style=\"text-align:center\">2016-08-08</td>\n<td style=\"text-align:center\">1.1.5</td>\n<td style=\"text-align:center\">2017-03-22</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.2</td>\n<td style=\"text-align:center\">2017-02-06</td>\n<td style=\"text-align:center\">1.2.1</td>\n<td style=\"text-align:center\">2017-04-26</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.3</td>\n<td style=\"text-align:center\">2017-06-01</td>\n<td style=\"text-align:center\">1.3.3</td>\n<td style=\"text-align:center\">2018-03-15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.4</td>\n<td style=\"text-align:center\">2017-12-12</td>\n<td style=\"text-align:center\">1.4.2</td>\n<td style=\"text-align:center\">2018-03-08</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.5</td>\n<td style=\"text-align:center\">2018-05-25</td>\n<td style=\"text-align:center\">1.5.6</td>\n<td style=\"text-align:center\">2018-12-26</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.6</td>\n<td style=\"text-align:center\">2018-08-08</td>\n<td style=\"text-align:center\">1.6.3</td>\n<td style=\"text-align:center\">2018-12-22</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">1.7</td>\n<td style=\"text-align:center\">2018-11-30</td>\n<td style=\"text-align:center\">1.7.2</td>\n<td style=\"text-align:center\">2019-02-15</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>1.8</strong></td>\n<td style=\"text-align:center\">2019-04-09</td>\n<td style=\"text-align:center\">1.8.0</td>\n<td style=\"text-align:center\">2019-04-09</td>\n</tr>\n</tbody>\n</table>\n"}],"PostAsset":[{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/rdd.png","slug":"rdd.png","post":"cjvne0b3j0001m7z4indi45ea","modified":1,"renderable":0},{"_id":"source/_posts/SparkStreaming反压机制详解/RateController.png","post":"cjvne0b360000m7z4s6s1pbj4","slug":"RateController.png","modified":1,"renderable":1},{"_id":"source/_posts/SparkStreaming反压机制详解/inputRate.png","post":"cjvne0b360000m7z4s6s1pbj4","slug":"inputRate.png","modified":1,"renderable":1},{"_id":"source/_posts/SparkStreaming反压机制详解/maxMessagesPerPartition.png","post":"cjvne0b360000m7z4s6s1pbj4","slug":"maxMessagesPerPartition.png","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/RDDUml","post":"cjvne0b3j0001m7z4indi45ea","slug":"RDDUml","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/RDDUml.png","post":"cjvne0b3j0001m7z4indi45ea","slug":"RDDUml.png","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SchedulerUML","post":"cjvne0b3j0001m7z4indi45ea","slug":"SchedulerUML","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SchedulerUML.png","post":"cjvne0b3j0001m7z4indi45ea","slug":"SchedulerUML.png","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SparkContextUML.png","post":"cjvne0b3j0001m7z4indi45ea","slug":"SparkContextUML.png","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SplitUML","post":"cjvne0b3j0001m7z4indi45ea","slug":"SplitUML","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/SplitUML.png","post":"cjvne0b3j0001m7z4indi45ea","slug":"SplitUML.png","modified":1,"renderable":1},{"_id":"source/_posts/spark源码解析alpha-0-1RDD与任务调度/TaskUML","post":"cjvne0b3j0001m7z4indi45ea","slug":"TaskUML","modified":1,"renderable":1}],"PostCategory":[],"PostTag":[{"post_id":"cjvne0b360000m7z4s6s1pbj4","tag_id":"cjvne0b3n0002m7z4cwh704u1","_id":"cjvne0b460006m7z4rx7sfnap"},{"post_id":"cjvne0b3j0001m7z4indi45ea","tag_id":"cjvne0b450005m7z4jedxd7ge","_id":"cjvne0b470007m7z4nk42hzrq"},{"post_id":"cjvne0b4c0008m7z4tv239dyf","tag_id":"cjvne0b4e0009m7z4208p4jo8","_id":"cjvne0b4f000am7z4pncg2n08"}],"Tag":[{"name":"spark","_id":"cjvne0b3n0002m7z4cwh704u1"},{"name":"spark,原理,源码","_id":"cjvne0b450005m7z4jedxd7ge"},{"name":"flink","_id":"cjvne0b4e0009m7z4208p4jo8"}]}}